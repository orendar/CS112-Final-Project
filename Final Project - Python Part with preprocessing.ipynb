{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from fastai.structured import *\n",
    "from fastai.column_data import *\n",
    "np.set_printoptions(threshold=50, edgeitems=20)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "PATH = '/Users/orendar/Downloads/dataverse_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>camp.length</th>\n",
       "      <th>deminc</th>\n",
       "      <th>base.poll</th>\n",
       "      <th>base.und</th>\n",
       "      <th>office</th>\n",
       "      <th>d.gone.neg</th>\n",
       "      <th>d.gone.neg.l1</th>\n",
       "      <th>d.gone.neg.l2</th>\n",
       "      <th>d.neg.frac.l3</th>\n",
       "      <th>...</th>\n",
       "      <th>rep.contrib.l1</th>\n",
       "      <th>race</th>\n",
       "      <th>first.week</th>\n",
       "      <th>num.dem</th>\n",
       "      <th>demprcnt</th>\n",
       "      <th>d.neg.rec</th>\n",
       "      <th>rep.contrib.l2</th>\n",
       "      <th>d.neg.dur</th>\n",
       "      <th>dem.polls.l2</th>\n",
       "      <th>pos.prob.subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>132545.00</td>\n",
       "      <td>AL-1-2002</td>\n",
       "      <td>-22</td>\n",
       "      <td>303</td>\n",
       "      <td>49.883698</td>\n",
       "      <td>0</td>\n",
       "      <td>102559.36</td>\n",
       "      <td>0</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>522327.00</td>\n",
       "      <td>AL-1-2002</td>\n",
       "      <td>-22</td>\n",
       "      <td>232</td>\n",
       "      <td>49.883698</td>\n",
       "      <td>0</td>\n",
       "      <td>132545.00</td>\n",
       "      <td>0</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>177739.44</td>\n",
       "      <td>AL-1-2002</td>\n",
       "      <td>-22</td>\n",
       "      <td>805</td>\n",
       "      <td>49.883698</td>\n",
       "      <td>2</td>\n",
       "      <td>138533.00</td>\n",
       "      <td>2</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>543465.00</td>\n",
       "      <td>AL-1-2002</td>\n",
       "      <td>-22</td>\n",
       "      <td>748</td>\n",
       "      <td>49.883698</td>\n",
       "      <td>3</td>\n",
       "      <td>177739.44</td>\n",
       "      <td>3</td>\n",
       "      <td>48.536252</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2002</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>2415314.50</td>\n",
       "      <td>AL-1-2002</td>\n",
       "      <td>-22</td>\n",
       "      <td>830</td>\n",
       "      <td>49.883698</td>\n",
       "      <td>4</td>\n",
       "      <td>543465.00</td>\n",
       "      <td>4</td>\n",
       "      <td>48.863636</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  camp.length  deminc  base.poll  base.und  office  d.gone.neg  \\\n",
       "1  2002           23       1  45.744681       6.0       0           0   \n",
       "2  2002           23       1  45.744681       6.0       0           0   \n",
       "3  2002           23       1  45.744681       6.0       0           1   \n",
       "4  2002           23       1  45.744681       6.0       0           1   \n",
       "5  2002           23       1  45.744681       6.0       0           1   \n",
       "\n",
       "   d.gone.neg.l1  d.gone.neg.l2  d.neg.frac.l3       ...         \\\n",
       "1              0              0       0.000000       ...          \n",
       "2              0              0       0.000000       ...          \n",
       "3              1              0       0.000000       ...          \n",
       "4              1              1       0.000000       ...          \n",
       "5              1              1       0.071429       ...          \n",
       "\n",
       "   rep.contrib.l1       race  first.week  num.dem   demprcnt  d.neg.rec  \\\n",
       "1       132545.00  AL-1-2002         -22      303  49.883698          0   \n",
       "2       522327.00  AL-1-2002         -22      232  49.883698          0   \n",
       "3       177739.44  AL-1-2002         -22      805  49.883698          2   \n",
       "4       543465.00  AL-1-2002         -22      748  49.883698          3   \n",
       "5      2415314.50  AL-1-2002         -22      830  49.883698          4   \n",
       "\n",
       "   rep.contrib.l2  d.neg.dur  dem.polls.l2  pos.prob.subset  \n",
       "1       102559.36          0     45.744681             True  \n",
       "2       132545.00          0     45.744681             True  \n",
       "3       138533.00          2     45.744681             True  \n",
       "4       177739.44          3     48.536252             True  \n",
       "5       543465.00          4     48.863636             True  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(f'{PATH}train_raw.csv', index_col = 0)\n",
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>camp.length</th>\n",
       "      <th>deminc</th>\n",
       "      <th>base.poll</th>\n",
       "      <th>base.und</th>\n",
       "      <th>office</th>\n",
       "      <th>d.gone.neg</th>\n",
       "      <th>d.gone.neg.l1</th>\n",
       "      <th>d.gone.neg.l2</th>\n",
       "      <th>d.neg.frac.l3</th>\n",
       "      <th>...</th>\n",
       "      <th>rep.contrib.l1</th>\n",
       "      <th>race</th>\n",
       "      <th>first.week</th>\n",
       "      <th>num.dem</th>\n",
       "      <th>demprcnt</th>\n",
       "      <th>d.neg.rec</th>\n",
       "      <th>rep.contrib.l2</th>\n",
       "      <th>d.neg.dur</th>\n",
       "      <th>dem.polls.l2</th>\n",
       "      <th>pos.prob.subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>44.736842</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>289158.00</td>\n",
       "      <td>CO-2-2002</td>\n",
       "      <td>-12</td>\n",
       "      <td>443</td>\n",
       "      <td>47.446492</td>\n",
       "      <td>5</td>\n",
       "      <td>344029.00</td>\n",
       "      <td>6</td>\n",
       "      <td>48.648649</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>63.636364</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34550.00</td>\n",
       "      <td>NM-1-2006</td>\n",
       "      <td>-22</td>\n",
       "      <td>374</td>\n",
       "      <td>68.817354</td>\n",
       "      <td>0</td>\n",
       "      <td>8641.00</td>\n",
       "      <td>0</td>\n",
       "      <td>70.114943</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>62.765957</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>31510.13</td>\n",
       "      <td>NM-1-2002</td>\n",
       "      <td>-22</td>\n",
       "      <td>362</td>\n",
       "      <td>58.696455</td>\n",
       "      <td>5</td>\n",
       "      <td>390706.48</td>\n",
       "      <td>6</td>\n",
       "      <td>60.674157</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>62.637363</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>219018.00</td>\n",
       "      <td>WV-2-2006</td>\n",
       "      <td>-26</td>\n",
       "      <td>160</td>\n",
       "      <td>65.646693</td>\n",
       "      <td>0</td>\n",
       "      <td>194750.00</td>\n",
       "      <td>2</td>\n",
       "      <td>67.741935</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>66.455237</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>91269.03</td>\n",
       "      <td>TN-1-2006</td>\n",
       "      <td>-14</td>\n",
       "      <td>642</td>\n",
       "      <td>69.756769</td>\n",
       "      <td>0</td>\n",
       "      <td>66217.39</td>\n",
       "      <td>0</td>\n",
       "      <td>66.455237</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  camp.length  deminc  base.poll  base.und  office  d.gone.neg  \\\n",
       "1  2002           13       0  44.736842      24.0       1           1   \n",
       "2  2006           23       1  63.636364      12.0       0           0   \n",
       "3  2002           23       0  62.765957       6.0       0           1   \n",
       "4  2006           27       1  62.637363       9.0       1           0   \n",
       "5  2006           15       1  66.455237       9.0       0           0   \n",
       "\n",
       "   d.gone.neg.l1  d.gone.neg.l2  d.neg.frac.l3       ...         \\\n",
       "1              1              1       1.000000       ...          \n",
       "2              0              0       0.000000       ...          \n",
       "3              1              1       0.176471       ...          \n",
       "4              0              0       0.090909       ...          \n",
       "5              0              0       0.000000       ...          \n",
       "\n",
       "   rep.contrib.l1       race  first.week  num.dem   demprcnt  d.neg.rec  \\\n",
       "1       289158.00  CO-2-2002         -12      443  47.446492          5   \n",
       "2        34550.00  NM-1-2006         -22      374  68.817354          0   \n",
       "3        31510.13  NM-1-2002         -22      362  58.696455          5   \n",
       "4       219018.00  WV-2-2006         -26      160  65.646693          0   \n",
       "5        91269.03  TN-1-2006         -14      642  69.756769          0   \n",
       "\n",
       "   rep.contrib.l2  d.neg.dur  dem.polls.l2  pos.prob.subset  \n",
       "1       344029.00          6     48.648649             True  \n",
       "2         8641.00          0     70.114943             True  \n",
       "3       390706.48          6     60.674157             True  \n",
       "4       194750.00          2     67.741935             True  \n",
       "5        66217.39          0     66.455237             True  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(f'{PATH}test_raw.csv',  index_col = 0)\n",
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\"deminc\", \"d.gone.neg.l1\", \"d.gone.neg.l2\", \"week\", \"year\",\n",
    "                \"office\"]\n",
    "\n",
    "cont_features = [\"base.poll\", \"r.neg.frac.l2\", \"r.neg.frac.l3\", \"rep.contrib.l1\", \n",
    "                 \"rep.contrib.l2\", \"dem.contrib.l1\", \"dem.contrib.l2\", \"num.rep.l1\",\n",
    "                 \"num.rep.l2\", \"num.dem.l1\", \"num.dem.l2\", \"d.neg.frac.l3\", \"undother.l2\",\n",
    "                 \"undother.l1\", \"camp.length\", \"base.und\", \"dem.polls.l1\", \"dem.polls.l2\",\n",
    "                \"neg.rep.l1\", \"neg.rep.l2\"]\n",
    "\n",
    "target = \"d.gone.neg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((863, 40), (863,), (287, 40), (287,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[cat_features+cont_features+[target]]\n",
    "x_train, y_train, nas, mapper = proc_df(train_df, target, do_scale=True)\n",
    "\n",
    "test_df = test_df[cat_features+cont_features+[target]]\n",
    "x_test, y_test, nas, mapper = proc_df(test_df, target, do_scale=True, mapper=mapper, na_dict=nas)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import *\n",
    "from sklearn.metrics import *\n",
    "rs = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=100, max_features='sqrt', random_state=rs)\n",
    "rfc = RandomForestClassifier(n_estimators=500, random_state=rs, n_jobs=-1)\n",
    "etc = ExtraTreesClassifier(n_estimators=500, random_state=rs, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc.fit(x_train, y_train)\n",
    "rfc.fit(x_train, y_train)\n",
    "etc.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_preds = gbc.predict(x_test)\n",
    "rfc_preds = rfc.predict(x_test)\n",
    "etc_preds = etc.predict(x_test)\n",
    "gbc_prob_preds = gbc.predict_proba(x_test)\n",
    "rfc_prob_preds = rfc.predict_proba(x_test)\n",
    "etc_prob_preds = etc.predict_proba(x_test)\n",
    "gbc_pos = gbc_prob_preds.T[1]\n",
    "rfc_pos = rfc_prob_preds.T[1]\n",
    "etc_pos = etc_prob_preds.T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(preds): return mean_squared_error(y_test, preds)**.5\n",
    "def auroc(preds): return roc_auc_score(y_test, preds)\n",
    "def accuracy(preds): return accuracy_score(y_test, preds)\n",
    "def logloss(preds): return log_loss(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.288994977945639, 0.29558670176081964, 0.2991263469314788)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(gbc_pos), rmse(rfc_pos), rmse(etc_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8954703832752613, 0.8780487804878049, 0.867595818815331)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(gbc_preds), accuracy(rfc_preds), accuracy(etc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9440683430045133, 0.9414893617021276, 0.9408446163765312)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc(gbc_pos), auroc(rfc_pos), auroc(etc_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2802019953829483, 0.2960417907871699, 0.29041988818556763)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss(gbc_pos), logloss(rfc_pos), logloss(etc_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>LogLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBM</th>\n",
       "      <td>0.895470</td>\n",
       "      <td>0.288995</td>\n",
       "      <td>0.944068</td>\n",
       "      <td>0.280202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.295587</td>\n",
       "      <td>0.941489</td>\n",
       "      <td>0.296042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET</th>\n",
       "      <td>0.867596</td>\n",
       "      <td>0.299126</td>\n",
       "      <td>0.940845</td>\n",
       "      <td>0.290420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy      RMSE     AUROC   LogLoss\n",
       "GBM  0.895470  0.288995  0.944068  0.280202\n",
       "RF   0.878049  0.295587  0.941489  0.296042\n",
       "ET   0.867596  0.299126  0.940845  0.290420"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=[[accuracy(gbc_preds), rmse(gbc_pos), auroc(gbc_pos), logloss(gbc_pos)],\n",
    "                        [accuracy(rfc_preds), rmse(rfc_pos), auroc(rfc_pos), logloss(rfc_pos)],\n",
    "                        [accuracy(etc_preds), rmse(etc_pos), auroc(etc_pos), logloss(etc_pos)]],\n",
    "                  index=['GBM', 'RF', 'ET'],\n",
    "                  columns=['Accuracy', 'RMSE', 'AUROC', 'LogLoss'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrrrr}\\n\\\\toprule\\n{} &  Accuracy &      RMSE &     AUROC &   LogLoss \\\\\\\\\\n\\\\midrule\\nGBM &  0.895470 &  0.288995 &  0.944068 &  0.280202 \\\\\\\\\\nRF  &  0.878049 &  0.295587 &  0.941489 &  0.296042 \\\\\\\\\\nET  &  0.867596 &  0.299126 &  0.940845 &  0.290420 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orendar/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.utils import *\n",
    "from keras.optimizers import *\n",
    "from sklearn.preprocessing import *\n",
    "from clr import *\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_norm = scaler.fit_transform(x_train)\n",
    "x_test_norm = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4096, input_dim=40, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "opt = optimizers.adam(amsgrad=True)\n",
    "#opt = optimizers.SGD(momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['mse', 'accuracy'])\n",
    "\n",
    "#callbacks arsenal\n",
    "def sched(idx, lr): return lr*0.9 if idx % 10 == 0 else lr\n",
    "lrsched = LearningRateScheduler(sched, verbose=0)\n",
    "reducelr = ReduceLROnPlateau(factor=0.8, patience=2)\n",
    "stop = EarlyStopping(patience=50)\n",
    "clr = CyclicLR(base_lr=1e-5, max_lr=1e-4, step_size=15, mode='triangular', scale_mode='cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 863 samples, validate on 287 samples\n",
      "Epoch 1/3000\n",
      " - 0s - loss: 0.7162 - mean_squared_error: 0.2614 - acc: 0.3801 - val_loss: 0.7130 - val_mean_squared_error: 0.2599 - val_acc: 0.3693\n",
      "Epoch 2/3000\n",
      " - 0s - loss: 0.7122 - mean_squared_error: 0.2594 - acc: 0.4114 - val_loss: 0.7035 - val_mean_squared_error: 0.2552 - val_acc: 0.4216\n",
      "Epoch 3/3000\n",
      " - 0s - loss: 0.7011 - mean_squared_error: 0.2539 - acc: 0.4531 - val_loss: 0.6903 - val_mean_squared_error: 0.2486 - val_acc: 0.5192\n",
      "Epoch 4/3000\n",
      " - 0s - loss: 0.6897 - mean_squared_error: 0.2483 - acc: 0.5110 - val_loss: 0.6734 - val_mean_squared_error: 0.2402 - val_acc: 0.6794\n",
      "Epoch 5/3000\n",
      " - 0s - loss: 0.6715 - mean_squared_error: 0.2393 - acc: 0.6188 - val_loss: 0.6535 - val_mean_squared_error: 0.2303 - val_acc: 0.7700\n",
      "Epoch 6/3000\n",
      " - 0s - loss: 0.6464 - mean_squared_error: 0.2270 - acc: 0.7358 - val_loss: 0.6312 - val_mean_squared_error: 0.2194 - val_acc: 0.7979\n",
      "Epoch 7/3000\n",
      " - 0s - loss: 0.6300 - mean_squared_error: 0.2189 - acc: 0.7659 - val_loss: 0.6076 - val_mean_squared_error: 0.2080 - val_acc: 0.8223\n",
      "Epoch 8/3000\n",
      " - 0s - loss: 0.6040 - mean_squared_error: 0.2066 - acc: 0.7752 - val_loss: 0.5835 - val_mean_squared_error: 0.1967 - val_acc: 0.8223\n",
      "Epoch 9/3000\n",
      " - 0s - loss: 0.5824 - mean_squared_error: 0.1966 - acc: 0.7961 - val_loss: 0.5634 - val_mean_squared_error: 0.1876 - val_acc: 0.8118\n",
      "Epoch 10/3000\n",
      " - 0s - loss: 0.5631 - mean_squared_error: 0.1877 - acc: 0.8134 - val_loss: 0.5477 - val_mean_squared_error: 0.1806 - val_acc: 0.8153\n",
      "Epoch 11/3000\n",
      " - 0s - loss: 0.5488 - mean_squared_error: 0.1814 - acc: 0.8030 - val_loss: 0.5358 - val_mean_squared_error: 0.1754 - val_acc: 0.8118\n",
      "Epoch 12/3000\n",
      " - 0s - loss: 0.5396 - mean_squared_error: 0.1773 - acc: 0.7995 - val_loss: 0.5267 - val_mean_squared_error: 0.1716 - val_acc: 0.8118\n",
      "Epoch 13/3000\n",
      " - 0s - loss: 0.5290 - mean_squared_error: 0.1727 - acc: 0.7972 - val_loss: 0.5202 - val_mean_squared_error: 0.1688 - val_acc: 0.8223\n",
      "Epoch 14/3000\n",
      " - 0s - loss: 0.5221 - mean_squared_error: 0.1696 - acc: 0.8053 - val_loss: 0.5157 - val_mean_squared_error: 0.1669 - val_acc: 0.8223\n",
      "Epoch 15/3000\n",
      " - 0s - loss: 0.5198 - mean_squared_error: 0.1686 - acc: 0.8146 - val_loss: 0.5131 - val_mean_squared_error: 0.1658 - val_acc: 0.8223\n",
      "Epoch 16/3000\n",
      " - 0s - loss: 0.5171 - mean_squared_error: 0.1677 - acc: 0.8134 - val_loss: 0.5114 - val_mean_squared_error: 0.1651 - val_acc: 0.8223\n",
      "Epoch 17/3000\n",
      " - 0s - loss: 0.5180 - mean_squared_error: 0.1680 - acc: 0.8007 - val_loss: 0.5082 - val_mean_squared_error: 0.1638 - val_acc: 0.8223\n",
      "Epoch 18/3000\n",
      " - 0s - loss: 0.5145 - mean_squared_error: 0.1665 - acc: 0.8065 - val_loss: 0.5036 - val_mean_squared_error: 0.1619 - val_acc: 0.8223\n",
      "Epoch 19/3000\n",
      " - 0s - loss: 0.5096 - mean_squared_error: 0.1645 - acc: 0.8065 - val_loss: 0.4979 - val_mean_squared_error: 0.1595 - val_acc: 0.8223\n",
      "Epoch 20/3000\n",
      " - 0s - loss: 0.5047 - mean_squared_error: 0.1623 - acc: 0.8134 - val_loss: 0.4911 - val_mean_squared_error: 0.1568 - val_acc: 0.8223\n",
      "Epoch 21/3000\n",
      " - 0s - loss: 0.4962 - mean_squared_error: 0.1592 - acc: 0.8239 - val_loss: 0.4835 - val_mean_squared_error: 0.1537 - val_acc: 0.8258\n",
      "Epoch 22/3000\n",
      " - 0s - loss: 0.4896 - mean_squared_error: 0.1566 - acc: 0.8192 - val_loss: 0.4753 - val_mean_squared_error: 0.1504 - val_acc: 0.8258\n",
      "Epoch 23/3000\n",
      " - 0s - loss: 0.4794 - mean_squared_error: 0.1522 - acc: 0.8169 - val_loss: 0.4666 - val_mean_squared_error: 0.1471 - val_acc: 0.8223\n",
      "Epoch 24/3000\n",
      " - 0s - loss: 0.4716 - mean_squared_error: 0.1490 - acc: 0.8297 - val_loss: 0.4591 - val_mean_squared_error: 0.1441 - val_acc: 0.8258\n",
      "Epoch 25/3000\n",
      " - 0s - loss: 0.4657 - mean_squared_error: 0.1469 - acc: 0.8134 - val_loss: 0.4530 - val_mean_squared_error: 0.1418 - val_acc: 0.8258\n",
      "Epoch 26/3000\n",
      " - 0s - loss: 0.4623 - mean_squared_error: 0.1456 - acc: 0.8262 - val_loss: 0.4481 - val_mean_squared_error: 0.1399 - val_acc: 0.8293\n",
      "Epoch 27/3000\n",
      " - 0s - loss: 0.4580 - mean_squared_error: 0.1441 - acc: 0.8216 - val_loss: 0.4443 - val_mean_squared_error: 0.1385 - val_acc: 0.8362\n",
      "Epoch 28/3000\n",
      " - 0s - loss: 0.4550 - mean_squared_error: 0.1427 - acc: 0.8250 - val_loss: 0.4414 - val_mean_squared_error: 0.1374 - val_acc: 0.8362\n",
      "Epoch 29/3000\n",
      " - 0s - loss: 0.4481 - mean_squared_error: 0.1399 - acc: 0.8308 - val_loss: 0.4395 - val_mean_squared_error: 0.1367 - val_acc: 0.8362\n",
      "Epoch 30/3000\n",
      " - 0s - loss: 0.4484 - mean_squared_error: 0.1403 - acc: 0.8297 - val_loss: 0.4383 - val_mean_squared_error: 0.1363 - val_acc: 0.8362\n",
      "Epoch 31/3000\n",
      " - 0s - loss: 0.4464 - mean_squared_error: 0.1395 - acc: 0.8308 - val_loss: 0.4375 - val_mean_squared_error: 0.1360 - val_acc: 0.8362\n",
      "Epoch 32/3000\n",
      " - 0s - loss: 0.4448 - mean_squared_error: 0.1387 - acc: 0.8273 - val_loss: 0.4361 - val_mean_squared_error: 0.1354 - val_acc: 0.8328\n",
      "Epoch 33/3000\n",
      " - 0s - loss: 0.4460 - mean_squared_error: 0.1396 - acc: 0.8204 - val_loss: 0.4340 - val_mean_squared_error: 0.1346 - val_acc: 0.8328\n",
      "Epoch 34/3000\n",
      " - 0s - loss: 0.4464 - mean_squared_error: 0.1394 - acc: 0.8297 - val_loss: 0.4312 - val_mean_squared_error: 0.1336 - val_acc: 0.8328\n",
      "Epoch 35/3000\n",
      " - 0s - loss: 0.4432 - mean_squared_error: 0.1380 - acc: 0.8389 - val_loss: 0.4280 - val_mean_squared_error: 0.1323 - val_acc: 0.8328\n",
      "Epoch 36/3000\n",
      " - 0s - loss: 0.4368 - mean_squared_error: 0.1357 - acc: 0.8331 - val_loss: 0.4242 - val_mean_squared_error: 0.1309 - val_acc: 0.8362\n",
      "Epoch 37/3000\n",
      " - 0s - loss: 0.4337 - mean_squared_error: 0.1346 - acc: 0.8308 - val_loss: 0.4200 - val_mean_squared_error: 0.1293 - val_acc: 0.8362\n",
      "Epoch 38/3000\n",
      " - 0s - loss: 0.4279 - mean_squared_error: 0.1325 - acc: 0.8355 - val_loss: 0.4153 - val_mean_squared_error: 0.1276 - val_acc: 0.8397\n",
      "Epoch 39/3000\n",
      " - 0s - loss: 0.4252 - mean_squared_error: 0.1316 - acc: 0.8413 - val_loss: 0.4112 - val_mean_squared_error: 0.1261 - val_acc: 0.8397\n",
      "Epoch 40/3000\n",
      " - 0s - loss: 0.4212 - mean_squared_error: 0.1300 - acc: 0.8436 - val_loss: 0.4078 - val_mean_squared_error: 0.1248 - val_acc: 0.8432\n",
      "Epoch 41/3000\n",
      " - 0s - loss: 0.4173 - mean_squared_error: 0.1284 - acc: 0.8343 - val_loss: 0.4050 - val_mean_squared_error: 0.1238 - val_acc: 0.8432\n",
      "Epoch 42/3000\n",
      " - 0s - loss: 0.4192 - mean_squared_error: 0.1292 - acc: 0.8389 - val_loss: 0.4028 - val_mean_squared_error: 0.1230 - val_acc: 0.8502\n",
      "Epoch 43/3000\n",
      " - 0s - loss: 0.4162 - mean_squared_error: 0.1282 - acc: 0.8436 - val_loss: 0.4011 - val_mean_squared_error: 0.1224 - val_acc: 0.8502\n",
      "Epoch 44/3000\n",
      " - 0s - loss: 0.4111 - mean_squared_error: 0.1263 - acc: 0.8459 - val_loss: 0.3999 - val_mean_squared_error: 0.1219 - val_acc: 0.8502\n",
      "Epoch 45/3000\n",
      " - 0s - loss: 0.4089 - mean_squared_error: 0.1253 - acc: 0.8436 - val_loss: 0.3992 - val_mean_squared_error: 0.1217 - val_acc: 0.8502\n",
      "Epoch 46/3000\n",
      " - 0s - loss: 0.4073 - mean_squared_error: 0.1248 - acc: 0.8424 - val_loss: 0.3987 - val_mean_squared_error: 0.1215 - val_acc: 0.8502\n",
      "Epoch 47/3000\n",
      " - 0s - loss: 0.4093 - mean_squared_error: 0.1256 - acc: 0.8413 - val_loss: 0.3978 - val_mean_squared_error: 0.1211 - val_acc: 0.8502\n",
      "Epoch 48/3000\n",
      " - 0s - loss: 0.4107 - mean_squared_error: 0.1261 - acc: 0.8436 - val_loss: 0.3965 - val_mean_squared_error: 0.1207 - val_acc: 0.8502\n",
      "Epoch 49/3000\n",
      " - 0s - loss: 0.4081 - mean_squared_error: 0.1253 - acc: 0.8436 - val_loss: 0.3947 - val_mean_squared_error: 0.1200 - val_acc: 0.8502\n",
      "Epoch 50/3000\n",
      " - 0s - loss: 0.4031 - mean_squared_error: 0.1234 - acc: 0.8447 - val_loss: 0.3926 - val_mean_squared_error: 0.1193 - val_acc: 0.8502\n",
      "Epoch 51/3000\n",
      " - 0s - loss: 0.4046 - mean_squared_error: 0.1242 - acc: 0.8447 - val_loss: 0.3902 - val_mean_squared_error: 0.1184 - val_acc: 0.8502\n",
      "Epoch 52/3000\n",
      " - 0s - loss: 0.4019 - mean_squared_error: 0.1231 - acc: 0.8447 - val_loss: 0.3875 - val_mean_squared_error: 0.1174 - val_acc: 0.8502\n",
      "Epoch 53/3000\n",
      " - 0s - loss: 0.4011 - mean_squared_error: 0.1231 - acc: 0.8494 - val_loss: 0.3845 - val_mean_squared_error: 0.1163 - val_acc: 0.8502\n",
      "Epoch 54/3000\n",
      " - 0s - loss: 0.3948 - mean_squared_error: 0.1204 - acc: 0.8517 - val_loss: 0.3817 - val_mean_squared_error: 0.1153 - val_acc: 0.8502\n",
      "Epoch 55/3000\n",
      " - 0s - loss: 0.3933 - mean_squared_error: 0.1199 - acc: 0.8470 - val_loss: 0.3795 - val_mean_squared_error: 0.1145 - val_acc: 0.8502\n",
      "Epoch 56/3000\n",
      " - 0s - loss: 0.3921 - mean_squared_error: 0.1194 - acc: 0.8494 - val_loss: 0.3777 - val_mean_squared_error: 0.1139 - val_acc: 0.8502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/3000\n",
      " - 0s - loss: 0.3887 - mean_squared_error: 0.1178 - acc: 0.8528 - val_loss: 0.3762 - val_mean_squared_error: 0.1134 - val_acc: 0.8502\n",
      "Epoch 58/3000\n",
      " - 0s - loss: 0.3873 - mean_squared_error: 0.1175 - acc: 0.8656 - val_loss: 0.3750 - val_mean_squared_error: 0.1130 - val_acc: 0.8502\n",
      "Epoch 59/3000\n",
      " - 0s - loss: 0.3865 - mean_squared_error: 0.1172 - acc: 0.8575 - val_loss: 0.3742 - val_mean_squared_error: 0.1127 - val_acc: 0.8502\n",
      "Epoch 60/3000\n",
      " - 0s - loss: 0.3870 - mean_squared_error: 0.1178 - acc: 0.8517 - val_loss: 0.3737 - val_mean_squared_error: 0.1125 - val_acc: 0.8502\n",
      "Epoch 61/3000\n",
      " - 0s - loss: 0.3886 - mean_squared_error: 0.1183 - acc: 0.8528 - val_loss: 0.3734 - val_mean_squared_error: 0.1124 - val_acc: 0.8502\n",
      "Epoch 62/3000\n",
      " - 0s - loss: 0.3866 - mean_squared_error: 0.1173 - acc: 0.8494 - val_loss: 0.3727 - val_mean_squared_error: 0.1122 - val_acc: 0.8502\n",
      "Epoch 63/3000\n",
      " - 0s - loss: 0.3836 - mean_squared_error: 0.1165 - acc: 0.8505 - val_loss: 0.3718 - val_mean_squared_error: 0.1119 - val_acc: 0.8502\n",
      "Epoch 64/3000\n",
      " - 0s - loss: 0.3846 - mean_squared_error: 0.1166 - acc: 0.8552 - val_loss: 0.3706 - val_mean_squared_error: 0.1114 - val_acc: 0.8537\n",
      "Epoch 65/3000\n",
      " - 0s - loss: 0.3817 - mean_squared_error: 0.1155 - acc: 0.8610 - val_loss: 0.3690 - val_mean_squared_error: 0.1109 - val_acc: 0.8537\n",
      "Epoch 66/3000\n",
      " - 0s - loss: 0.3821 - mean_squared_error: 0.1159 - acc: 0.8586 - val_loss: 0.3673 - val_mean_squared_error: 0.1103 - val_acc: 0.8537\n",
      "Epoch 67/3000\n",
      " - 0s - loss: 0.3811 - mean_squared_error: 0.1158 - acc: 0.8494 - val_loss: 0.3652 - val_mean_squared_error: 0.1096 - val_acc: 0.8537\n",
      "Epoch 68/3000\n",
      " - 0s - loss: 0.3762 - mean_squared_error: 0.1134 - acc: 0.8610 - val_loss: 0.3629 - val_mean_squared_error: 0.1088 - val_acc: 0.8571\n",
      "Epoch 69/3000\n",
      " - 0s - loss: 0.3705 - mean_squared_error: 0.1114 - acc: 0.8644 - val_loss: 0.3609 - val_mean_squared_error: 0.1081 - val_acc: 0.8571\n",
      "Epoch 70/3000\n",
      " - 0s - loss: 0.3701 - mean_squared_error: 0.1115 - acc: 0.8621 - val_loss: 0.3591 - val_mean_squared_error: 0.1075 - val_acc: 0.8571\n",
      "Epoch 71/3000\n",
      " - 0s - loss: 0.3718 - mean_squared_error: 0.1123 - acc: 0.8586 - val_loss: 0.3576 - val_mean_squared_error: 0.1071 - val_acc: 0.8571\n",
      "Epoch 72/3000\n",
      " - 0s - loss: 0.3703 - mean_squared_error: 0.1118 - acc: 0.8621 - val_loss: 0.3565 - val_mean_squared_error: 0.1067 - val_acc: 0.8571\n",
      "Epoch 73/3000\n",
      " - 0s - loss: 0.3666 - mean_squared_error: 0.1107 - acc: 0.8667 - val_loss: 0.3556 - val_mean_squared_error: 0.1064 - val_acc: 0.8571\n",
      "Epoch 74/3000\n",
      " - 0s - loss: 0.3685 - mean_squared_error: 0.1115 - acc: 0.8610 - val_loss: 0.3550 - val_mean_squared_error: 0.1062 - val_acc: 0.8571\n",
      "Epoch 75/3000\n",
      " - 0s - loss: 0.3638 - mean_squared_error: 0.1099 - acc: 0.8679 - val_loss: 0.3546 - val_mean_squared_error: 0.1060 - val_acc: 0.8571\n",
      "Epoch 76/3000\n",
      " - 0s - loss: 0.3635 - mean_squared_error: 0.1094 - acc: 0.8621 - val_loss: 0.3543 - val_mean_squared_error: 0.1060 - val_acc: 0.8571\n",
      "Epoch 77/3000\n",
      " - 0s - loss: 0.3662 - mean_squared_error: 0.1102 - acc: 0.8621 - val_loss: 0.3538 - val_mean_squared_error: 0.1058 - val_acc: 0.8571\n",
      "Epoch 78/3000\n",
      " - 0s - loss: 0.3656 - mean_squared_error: 0.1099 - acc: 0.8633 - val_loss: 0.3531 - val_mean_squared_error: 0.1056 - val_acc: 0.8606\n",
      "Epoch 79/3000\n",
      " - 0s - loss: 0.3628 - mean_squared_error: 0.1094 - acc: 0.8667 - val_loss: 0.3522 - val_mean_squared_error: 0.1053 - val_acc: 0.8606\n",
      "Epoch 80/3000\n",
      " - 0s - loss: 0.3636 - mean_squared_error: 0.1095 - acc: 0.8621 - val_loss: 0.3511 - val_mean_squared_error: 0.1049 - val_acc: 0.8606\n",
      "Epoch 81/3000\n",
      " - 0s - loss: 0.3625 - mean_squared_error: 0.1088 - acc: 0.8691 - val_loss: 0.3498 - val_mean_squared_error: 0.1045 - val_acc: 0.8606\n",
      "Epoch 82/3000\n",
      " - 0s - loss: 0.3580 - mean_squared_error: 0.1076 - acc: 0.8691 - val_loss: 0.3482 - val_mean_squared_error: 0.1040 - val_acc: 0.8606\n",
      "Epoch 83/3000\n",
      " - 0s - loss: 0.3579 - mean_squared_error: 0.1073 - acc: 0.8714 - val_loss: 0.3465 - val_mean_squared_error: 0.1034 - val_acc: 0.8606\n",
      "Epoch 84/3000\n",
      " - 0s - loss: 0.3546 - mean_squared_error: 0.1068 - acc: 0.8702 - val_loss: 0.3450 - val_mean_squared_error: 0.1029 - val_acc: 0.8606\n",
      "Epoch 85/3000\n",
      " - 0s - loss: 0.3543 - mean_squared_error: 0.1065 - acc: 0.8714 - val_loss: 0.3438 - val_mean_squared_error: 0.1025 - val_acc: 0.8606\n",
      "Epoch 86/3000\n",
      " - 0s - loss: 0.3546 - mean_squared_error: 0.1064 - acc: 0.8725 - val_loss: 0.3427 - val_mean_squared_error: 0.1022 - val_acc: 0.8606\n",
      "Epoch 87/3000\n",
      " - 0s - loss: 0.3519 - mean_squared_error: 0.1056 - acc: 0.8656 - val_loss: 0.3418 - val_mean_squared_error: 0.1019 - val_acc: 0.8606\n",
      "Epoch 88/3000\n",
      " - 0s - loss: 0.3506 - mean_squared_error: 0.1055 - acc: 0.8667 - val_loss: 0.3412 - val_mean_squared_error: 0.1017 - val_acc: 0.8606\n",
      "Epoch 89/3000\n",
      " - 0s - loss: 0.3497 - mean_squared_error: 0.1044 - acc: 0.8749 - val_loss: 0.3407 - val_mean_squared_error: 0.1016 - val_acc: 0.8606\n",
      "Epoch 90/3000\n",
      " - 0s - loss: 0.3477 - mean_squared_error: 0.1039 - acc: 0.8725 - val_loss: 0.3405 - val_mean_squared_error: 0.1015 - val_acc: 0.8606\n",
      "Epoch 91/3000\n",
      " - 0s - loss: 0.3484 - mean_squared_error: 0.1043 - acc: 0.8725 - val_loss: 0.3403 - val_mean_squared_error: 0.1014 - val_acc: 0.8641\n",
      "Epoch 92/3000\n",
      " - 0s - loss: 0.3492 - mean_squared_error: 0.1047 - acc: 0.8679 - val_loss: 0.3399 - val_mean_squared_error: 0.1013 - val_acc: 0.8676\n",
      "Epoch 93/3000\n",
      " - 0s - loss: 0.3461 - mean_squared_error: 0.1037 - acc: 0.8644 - val_loss: 0.3393 - val_mean_squared_error: 0.1011 - val_acc: 0.8676\n",
      "Epoch 94/3000\n",
      " - 0s - loss: 0.3477 - mean_squared_error: 0.1040 - acc: 0.8760 - val_loss: 0.3386 - val_mean_squared_error: 0.1009 - val_acc: 0.8676\n",
      "Epoch 95/3000\n",
      " - 0s - loss: 0.3485 - mean_squared_error: 0.1042 - acc: 0.8737 - val_loss: 0.3377 - val_mean_squared_error: 0.1006 - val_acc: 0.8676\n",
      "Epoch 96/3000\n",
      " - 0s - loss: 0.3463 - mean_squared_error: 0.1038 - acc: 0.8702 - val_loss: 0.3367 - val_mean_squared_error: 0.1003 - val_acc: 0.8711\n",
      "Epoch 97/3000\n",
      " - 0s - loss: 0.3420 - mean_squared_error: 0.1018 - acc: 0.8772 - val_loss: 0.3355 - val_mean_squared_error: 0.0999 - val_acc: 0.8711\n",
      "Epoch 98/3000\n",
      " - 0s - loss: 0.3422 - mean_squared_error: 0.1021 - acc: 0.8737 - val_loss: 0.3341 - val_mean_squared_error: 0.0995 - val_acc: 0.8711\n",
      "Epoch 99/3000\n",
      " - 0s - loss: 0.3436 - mean_squared_error: 0.1027 - acc: 0.8725 - val_loss: 0.3329 - val_mean_squared_error: 0.0992 - val_acc: 0.8711\n",
      "Epoch 100/3000\n",
      " - 0s - loss: 0.3417 - mean_squared_error: 0.1023 - acc: 0.8737 - val_loss: 0.3318 - val_mean_squared_error: 0.0989 - val_acc: 0.8711\n",
      "Epoch 101/3000\n",
      " - 0s - loss: 0.3382 - mean_squared_error: 0.1010 - acc: 0.8725 - val_loss: 0.3310 - val_mean_squared_error: 0.0986 - val_acc: 0.8711\n",
      "Epoch 102/3000\n",
      " - 0s - loss: 0.3371 - mean_squared_error: 0.1003 - acc: 0.8760 - val_loss: 0.3302 - val_mean_squared_error: 0.0984 - val_acc: 0.8711\n",
      "Epoch 103/3000\n",
      " - 0s - loss: 0.3369 - mean_squared_error: 0.1008 - acc: 0.8737 - val_loss: 0.3297 - val_mean_squared_error: 0.0982 - val_acc: 0.8711\n",
      "Epoch 104/3000\n",
      " - 0s - loss: 0.3385 - mean_squared_error: 0.1010 - acc: 0.8783 - val_loss: 0.3293 - val_mean_squared_error: 0.0981 - val_acc: 0.8711\n",
      "Epoch 105/3000\n",
      " - 0s - loss: 0.3359 - mean_squared_error: 0.1005 - acc: 0.8737 - val_loss: 0.3291 - val_mean_squared_error: 0.0981 - val_acc: 0.8711\n",
      "Epoch 106/3000\n",
      " - 0s - loss: 0.3375 - mean_squared_error: 0.1010 - acc: 0.8725 - val_loss: 0.3290 - val_mean_squared_error: 0.0980 - val_acc: 0.8711\n",
      "Epoch 107/3000\n",
      " - 0s - loss: 0.3371 - mean_squared_error: 0.1006 - acc: 0.8760 - val_loss: 0.3287 - val_mean_squared_error: 0.0979 - val_acc: 0.8711\n",
      "Epoch 108/3000\n",
      " - 0s - loss: 0.3369 - mean_squared_error: 0.1010 - acc: 0.8737 - val_loss: 0.3282 - val_mean_squared_error: 0.0978 - val_acc: 0.8746\n",
      "Epoch 109/3000\n",
      " - 0s - loss: 0.3335 - mean_squared_error: 0.0998 - acc: 0.8772 - val_loss: 0.3277 - val_mean_squared_error: 0.0976 - val_acc: 0.8746\n",
      "Epoch 110/3000\n",
      " - 0s - loss: 0.3355 - mean_squared_error: 0.1000 - acc: 0.8783 - val_loss: 0.3269 - val_mean_squared_error: 0.0974 - val_acc: 0.8746\n",
      "Epoch 111/3000\n",
      " - 0s - loss: 0.3352 - mean_squared_error: 0.1002 - acc: 0.8783 - val_loss: 0.3261 - val_mean_squared_error: 0.0972 - val_acc: 0.8746\n",
      "Epoch 112/3000\n",
      " - 0s - loss: 0.3295 - mean_squared_error: 0.0977 - acc: 0.8783 - val_loss: 0.3250 - val_mean_squared_error: 0.0969 - val_acc: 0.8746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/3000\n",
      " - 0s - loss: 0.3306 - mean_squared_error: 0.0984 - acc: 0.8795 - val_loss: 0.3239 - val_mean_squared_error: 0.0965 - val_acc: 0.8746\n",
      "Epoch 114/3000\n",
      " - 0s - loss: 0.3275 - mean_squared_error: 0.0974 - acc: 0.8806 - val_loss: 0.3229 - val_mean_squared_error: 0.0963 - val_acc: 0.8746\n",
      "Epoch 115/3000\n",
      " - 0s - loss: 0.3296 - mean_squared_error: 0.0983 - acc: 0.8783 - val_loss: 0.3220 - val_mean_squared_error: 0.0960 - val_acc: 0.8746\n",
      "Epoch 116/3000\n",
      " - 0s - loss: 0.3267 - mean_squared_error: 0.0973 - acc: 0.8749 - val_loss: 0.3212 - val_mean_squared_error: 0.0958 - val_acc: 0.8746\n",
      "Epoch 117/3000\n",
      " - 0s - loss: 0.3267 - mean_squared_error: 0.0974 - acc: 0.8795 - val_loss: 0.3207 - val_mean_squared_error: 0.0957 - val_acc: 0.8746\n",
      "Epoch 118/3000\n",
      " - 0s - loss: 0.3246 - mean_squared_error: 0.0968 - acc: 0.8749 - val_loss: 0.3202 - val_mean_squared_error: 0.0955 - val_acc: 0.8746\n",
      "Epoch 119/3000\n",
      " - 0s - loss: 0.3239 - mean_squared_error: 0.0965 - acc: 0.8818 - val_loss: 0.3199 - val_mean_squared_error: 0.0955 - val_acc: 0.8746\n",
      "Epoch 120/3000\n",
      " - 0s - loss: 0.3247 - mean_squared_error: 0.0968 - acc: 0.8772 - val_loss: 0.3198 - val_mean_squared_error: 0.0954 - val_acc: 0.8746\n",
      "Epoch 121/3000\n",
      " - 0s - loss: 0.3230 - mean_squared_error: 0.0963 - acc: 0.8818 - val_loss: 0.3196 - val_mean_squared_error: 0.0954 - val_acc: 0.8746\n",
      "Epoch 122/3000\n",
      " - 0s - loss: 0.3236 - mean_squared_error: 0.0962 - acc: 0.8830 - val_loss: 0.3194 - val_mean_squared_error: 0.0953 - val_acc: 0.8746\n",
      "Epoch 123/3000\n",
      " - 0s - loss: 0.3220 - mean_squared_error: 0.0959 - acc: 0.8830 - val_loss: 0.3191 - val_mean_squared_error: 0.0952 - val_acc: 0.8746\n",
      "Epoch 124/3000\n",
      " - 0s - loss: 0.3240 - mean_squared_error: 0.0967 - acc: 0.8806 - val_loss: 0.3186 - val_mean_squared_error: 0.0951 - val_acc: 0.8746\n",
      "Epoch 125/3000\n",
      " - 0s - loss: 0.3227 - mean_squared_error: 0.0957 - acc: 0.8853 - val_loss: 0.3180 - val_mean_squared_error: 0.0950 - val_acc: 0.8746\n",
      "Epoch 126/3000\n",
      " - 0s - loss: 0.3207 - mean_squared_error: 0.0954 - acc: 0.8818 - val_loss: 0.3173 - val_mean_squared_error: 0.0948 - val_acc: 0.8746\n",
      "Epoch 127/3000\n",
      " - 0s - loss: 0.3203 - mean_squared_error: 0.0952 - acc: 0.8806 - val_loss: 0.3165 - val_mean_squared_error: 0.0946 - val_acc: 0.8746\n",
      "Epoch 128/3000\n",
      " - 0s - loss: 0.3194 - mean_squared_error: 0.0950 - acc: 0.8772 - val_loss: 0.3156 - val_mean_squared_error: 0.0944 - val_acc: 0.8746\n",
      "Epoch 129/3000\n",
      " - 0s - loss: 0.3191 - mean_squared_error: 0.0951 - acc: 0.8830 - val_loss: 0.3148 - val_mean_squared_error: 0.0942 - val_acc: 0.8746\n",
      "Epoch 130/3000\n",
      " - 0s - loss: 0.3173 - mean_squared_error: 0.0946 - acc: 0.8818 - val_loss: 0.3142 - val_mean_squared_error: 0.0940 - val_acc: 0.8711\n",
      "Epoch 131/3000\n",
      " - 0s - loss: 0.3145 - mean_squared_error: 0.0934 - acc: 0.8772 - val_loss: 0.3136 - val_mean_squared_error: 0.0939 - val_acc: 0.8711\n",
      "Epoch 132/3000\n",
      " - 0s - loss: 0.3156 - mean_squared_error: 0.0938 - acc: 0.8806 - val_loss: 0.3132 - val_mean_squared_error: 0.0937 - val_acc: 0.8711\n",
      "Epoch 133/3000\n",
      " - 0s - loss: 0.3139 - mean_squared_error: 0.0933 - acc: 0.8818 - val_loss: 0.3128 - val_mean_squared_error: 0.0937 - val_acc: 0.8711\n",
      "Epoch 134/3000\n",
      " - 0s - loss: 0.3147 - mean_squared_error: 0.0934 - acc: 0.8830 - val_loss: 0.3126 - val_mean_squared_error: 0.0936 - val_acc: 0.8711\n",
      "Epoch 135/3000\n",
      " - 0s - loss: 0.3132 - mean_squared_error: 0.0932 - acc: 0.8806 - val_loss: 0.3124 - val_mean_squared_error: 0.0936 - val_acc: 0.8711\n",
      "Epoch 136/3000\n",
      " - 0s - loss: 0.3147 - mean_squared_error: 0.0937 - acc: 0.8806 - val_loss: 0.3123 - val_mean_squared_error: 0.0935 - val_acc: 0.8711\n",
      "Epoch 137/3000\n",
      " - 0s - loss: 0.3149 - mean_squared_error: 0.0938 - acc: 0.8795 - val_loss: 0.3121 - val_mean_squared_error: 0.0935 - val_acc: 0.8711\n",
      "Epoch 138/3000\n",
      " - 0s - loss: 0.3148 - mean_squared_error: 0.0937 - acc: 0.8795 - val_loss: 0.3118 - val_mean_squared_error: 0.0934 - val_acc: 0.8711\n",
      "Epoch 139/3000\n",
      " - 0s - loss: 0.3141 - mean_squared_error: 0.0935 - acc: 0.8760 - val_loss: 0.3115 - val_mean_squared_error: 0.0933 - val_acc: 0.8711\n",
      "Epoch 140/3000\n",
      " - 0s - loss: 0.3131 - mean_squared_error: 0.0931 - acc: 0.8841 - val_loss: 0.3111 - val_mean_squared_error: 0.0932 - val_acc: 0.8711\n",
      "Epoch 141/3000\n",
      " - 0s - loss: 0.3101 - mean_squared_error: 0.0920 - acc: 0.8795 - val_loss: 0.3105 - val_mean_squared_error: 0.0931 - val_acc: 0.8711\n",
      "Epoch 142/3000\n",
      " - 0s - loss: 0.3105 - mean_squared_error: 0.0924 - acc: 0.8818 - val_loss: 0.3099 - val_mean_squared_error: 0.0929 - val_acc: 0.8711\n",
      "Epoch 143/3000\n",
      " - 0s - loss: 0.3095 - mean_squared_error: 0.0917 - acc: 0.8841 - val_loss: 0.3092 - val_mean_squared_error: 0.0928 - val_acc: 0.8746\n",
      "Epoch 144/3000\n",
      " - 0s - loss: 0.3079 - mean_squared_error: 0.0916 - acc: 0.8806 - val_loss: 0.3086 - val_mean_squared_error: 0.0926 - val_acc: 0.8746\n",
      "Epoch 145/3000\n",
      " - 0s - loss: 0.3042 - mean_squared_error: 0.0900 - acc: 0.8853 - val_loss: 0.3080 - val_mean_squared_error: 0.0925 - val_acc: 0.8746\n",
      "Epoch 146/3000\n",
      " - 0s - loss: 0.3069 - mean_squared_error: 0.0910 - acc: 0.8818 - val_loss: 0.3076 - val_mean_squared_error: 0.0924 - val_acc: 0.8746\n",
      "Epoch 147/3000\n",
      " - 0s - loss: 0.3045 - mean_squared_error: 0.0900 - acc: 0.8853 - val_loss: 0.3072 - val_mean_squared_error: 0.0923 - val_acc: 0.8746\n",
      "Epoch 148/3000\n",
      " - 0s - loss: 0.3064 - mean_squared_error: 0.0908 - acc: 0.8888 - val_loss: 0.3070 - val_mean_squared_error: 0.0922 - val_acc: 0.8746\n",
      "Epoch 149/3000\n",
      " - 0s - loss: 0.3080 - mean_squared_error: 0.0915 - acc: 0.8818 - val_loss: 0.3068 - val_mean_squared_error: 0.0922 - val_acc: 0.8746\n",
      "Epoch 150/3000\n",
      " - 0s - loss: 0.3044 - mean_squared_error: 0.0897 - acc: 0.8853 - val_loss: 0.3067 - val_mean_squared_error: 0.0921 - val_acc: 0.8746\n",
      "Epoch 151/3000\n",
      " - 0s - loss: 0.3061 - mean_squared_error: 0.0908 - acc: 0.8841 - val_loss: 0.3066 - val_mean_squared_error: 0.0921 - val_acc: 0.8746\n",
      "Epoch 152/3000\n",
      " - 0s - loss: 0.3039 - mean_squared_error: 0.0902 - acc: 0.8783 - val_loss: 0.3064 - val_mean_squared_error: 0.0921 - val_acc: 0.8746\n",
      "Epoch 153/3000\n",
      " - 0s - loss: 0.3068 - mean_squared_error: 0.0912 - acc: 0.8830 - val_loss: 0.3062 - val_mean_squared_error: 0.0920 - val_acc: 0.8746\n",
      "Epoch 154/3000\n",
      " - 0s - loss: 0.3069 - mean_squared_error: 0.0910 - acc: 0.8853 - val_loss: 0.3059 - val_mean_squared_error: 0.0920 - val_acc: 0.8746\n",
      "Epoch 155/3000\n",
      " - 0s - loss: 0.3046 - mean_squared_error: 0.0906 - acc: 0.8841 - val_loss: 0.3055 - val_mean_squared_error: 0.0919 - val_acc: 0.8746\n",
      "Epoch 156/3000\n",
      " - 0s - loss: 0.3050 - mean_squared_error: 0.0907 - acc: 0.8818 - val_loss: 0.3051 - val_mean_squared_error: 0.0918 - val_acc: 0.8746\n",
      "Epoch 157/3000\n",
      " - 0s - loss: 0.3042 - mean_squared_error: 0.0906 - acc: 0.8818 - val_loss: 0.3046 - val_mean_squared_error: 0.0917 - val_acc: 0.8746\n",
      "Epoch 158/3000\n",
      " - 0s - loss: 0.3019 - mean_squared_error: 0.0896 - acc: 0.8818 - val_loss: 0.3041 - val_mean_squared_error: 0.0916 - val_acc: 0.8746\n",
      "Epoch 159/3000\n",
      " - 0s - loss: 0.3018 - mean_squared_error: 0.0890 - acc: 0.8853 - val_loss: 0.3036 - val_mean_squared_error: 0.0915 - val_acc: 0.8746\n",
      "Epoch 160/3000\n",
      " - 0s - loss: 0.3003 - mean_squared_error: 0.0887 - acc: 0.8806 - val_loss: 0.3032 - val_mean_squared_error: 0.0914 - val_acc: 0.8746\n",
      "Epoch 161/3000\n",
      " - 0s - loss: 0.3003 - mean_squared_error: 0.0889 - acc: 0.8864 - val_loss: 0.3029 - val_mean_squared_error: 0.0913 - val_acc: 0.8746\n",
      "Epoch 162/3000\n",
      " - 0s - loss: 0.3002 - mean_squared_error: 0.0890 - acc: 0.8853 - val_loss: 0.3026 - val_mean_squared_error: 0.0913 - val_acc: 0.8746\n",
      "Epoch 163/3000\n",
      " - 0s - loss: 0.2972 - mean_squared_error: 0.0878 - acc: 0.8876 - val_loss: 0.3024 - val_mean_squared_error: 0.0912 - val_acc: 0.8746\n",
      "Epoch 164/3000\n",
      " - 0s - loss: 0.3030 - mean_squared_error: 0.0898 - acc: 0.8841 - val_loss: 0.3022 - val_mean_squared_error: 0.0912 - val_acc: 0.8746\n",
      "Epoch 165/3000\n",
      " - 0s - loss: 0.2956 - mean_squared_error: 0.0873 - acc: 0.8876 - val_loss: 0.3021 - val_mean_squared_error: 0.0912 - val_acc: 0.8746\n",
      "Epoch 166/3000\n",
      " - 0s - loss: 0.2975 - mean_squared_error: 0.0881 - acc: 0.8853 - val_loss: 0.3021 - val_mean_squared_error: 0.0912 - val_acc: 0.8746\n",
      "Epoch 167/3000\n",
      " - 0s - loss: 0.2999 - mean_squared_error: 0.0888 - acc: 0.8853 - val_loss: 0.3019 - val_mean_squared_error: 0.0911 - val_acc: 0.8746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/3000\n",
      " - 0s - loss: 0.2982 - mean_squared_error: 0.0879 - acc: 0.8853 - val_loss: 0.3017 - val_mean_squared_error: 0.0911 - val_acc: 0.8746\n",
      "Epoch 169/3000\n",
      " - 0s - loss: 0.2952 - mean_squared_error: 0.0872 - acc: 0.8911 - val_loss: 0.3015 - val_mean_squared_error: 0.0910 - val_acc: 0.8746\n",
      "Epoch 170/3000\n",
      " - 0s - loss: 0.2967 - mean_squared_error: 0.0875 - acc: 0.8853 - val_loss: 0.3012 - val_mean_squared_error: 0.0910 - val_acc: 0.8746\n",
      "Epoch 171/3000\n",
      " - 0s - loss: 0.2969 - mean_squared_error: 0.0880 - acc: 0.8864 - val_loss: 0.3009 - val_mean_squared_error: 0.0909 - val_acc: 0.8746\n",
      "Epoch 172/3000\n",
      " - 0s - loss: 0.2963 - mean_squared_error: 0.0880 - acc: 0.8853 - val_loss: 0.3005 - val_mean_squared_error: 0.0908 - val_acc: 0.8746\n",
      "Epoch 173/3000\n",
      " - 0s - loss: 0.2943 - mean_squared_error: 0.0870 - acc: 0.8841 - val_loss: 0.3001 - val_mean_squared_error: 0.0907 - val_acc: 0.8746\n",
      "Epoch 174/3000\n",
      " - 0s - loss: 0.2949 - mean_squared_error: 0.0873 - acc: 0.8876 - val_loss: 0.2997 - val_mean_squared_error: 0.0907 - val_acc: 0.8746\n",
      "Epoch 175/3000\n",
      " - 0s - loss: 0.2947 - mean_squared_error: 0.0873 - acc: 0.8864 - val_loss: 0.2994 - val_mean_squared_error: 0.0906 - val_acc: 0.8746\n",
      "Epoch 176/3000\n",
      " - 0s - loss: 0.2950 - mean_squared_error: 0.0874 - acc: 0.8853 - val_loss: 0.2991 - val_mean_squared_error: 0.0905 - val_acc: 0.8746\n",
      "Epoch 177/3000\n",
      " - 0s - loss: 0.2943 - mean_squared_error: 0.0872 - acc: 0.8876 - val_loss: 0.2989 - val_mean_squared_error: 0.0905 - val_acc: 0.8746\n",
      "Epoch 178/3000\n",
      " - 0s - loss: 0.2902 - mean_squared_error: 0.0857 - acc: 0.8864 - val_loss: 0.2987 - val_mean_squared_error: 0.0904 - val_acc: 0.8746\n",
      "Epoch 179/3000\n",
      " - 0s - loss: 0.2907 - mean_squared_error: 0.0858 - acc: 0.8876 - val_loss: 0.2985 - val_mean_squared_error: 0.0904 - val_acc: 0.8746\n",
      "Epoch 180/3000\n",
      " - 0s - loss: 0.2916 - mean_squared_error: 0.0863 - acc: 0.8830 - val_loss: 0.2985 - val_mean_squared_error: 0.0904 - val_acc: 0.8746\n",
      "Epoch 181/3000\n",
      " - 0s - loss: 0.2916 - mean_squared_error: 0.0863 - acc: 0.8876 - val_loss: 0.2984 - val_mean_squared_error: 0.0904 - val_acc: 0.8746\n",
      "Epoch 182/3000\n",
      " - 0s - loss: 0.2927 - mean_squared_error: 0.0866 - acc: 0.8853 - val_loss: 0.2983 - val_mean_squared_error: 0.0904 - val_acc: 0.8780\n",
      "Epoch 183/3000\n",
      " - 0s - loss: 0.2905 - mean_squared_error: 0.0862 - acc: 0.8841 - val_loss: 0.2982 - val_mean_squared_error: 0.0903 - val_acc: 0.8780\n",
      "Epoch 184/3000\n",
      " - 0s - loss: 0.2903 - mean_squared_error: 0.0861 - acc: 0.8899 - val_loss: 0.2980 - val_mean_squared_error: 0.0903 - val_acc: 0.8780\n",
      "Epoch 185/3000\n",
      " - 0s - loss: 0.2888 - mean_squared_error: 0.0852 - acc: 0.8899 - val_loss: 0.2977 - val_mean_squared_error: 0.0902 - val_acc: 0.8780\n",
      "Epoch 186/3000\n",
      " - 0s - loss: 0.2893 - mean_squared_error: 0.0853 - acc: 0.8888 - val_loss: 0.2974 - val_mean_squared_error: 0.0902 - val_acc: 0.8780\n",
      "Epoch 187/3000\n",
      " - 0s - loss: 0.2862 - mean_squared_error: 0.0844 - acc: 0.8922 - val_loss: 0.2971 - val_mean_squared_error: 0.0901 - val_acc: 0.8780\n",
      "Epoch 188/3000\n",
      " - 0s - loss: 0.2897 - mean_squared_error: 0.0854 - acc: 0.8899 - val_loss: 0.2967 - val_mean_squared_error: 0.0900 - val_acc: 0.8780\n",
      "Epoch 189/3000\n",
      " - 0s - loss: 0.2890 - mean_squared_error: 0.0853 - acc: 0.8946 - val_loss: 0.2963 - val_mean_squared_error: 0.0900 - val_acc: 0.8780\n",
      "Epoch 190/3000\n",
      " - 0s - loss: 0.2842 - mean_squared_error: 0.0837 - acc: 0.8876 - val_loss: 0.2959 - val_mean_squared_error: 0.0899 - val_acc: 0.8780\n",
      "Epoch 191/3000\n",
      " - 0s - loss: 0.2885 - mean_squared_error: 0.0849 - acc: 0.8876 - val_loss: 0.2957 - val_mean_squared_error: 0.0899 - val_acc: 0.8780\n",
      "Epoch 192/3000\n",
      " - 0s - loss: 0.2874 - mean_squared_error: 0.0851 - acc: 0.8876 - val_loss: 0.2955 - val_mean_squared_error: 0.0899 - val_acc: 0.8780\n",
      "Epoch 193/3000\n",
      " - 0s - loss: 0.2875 - mean_squared_error: 0.0845 - acc: 0.8853 - val_loss: 0.2954 - val_mean_squared_error: 0.0898 - val_acc: 0.8780\n",
      "Epoch 194/3000\n",
      " - 0s - loss: 0.2867 - mean_squared_error: 0.0847 - acc: 0.8876 - val_loss: 0.2953 - val_mean_squared_error: 0.0898 - val_acc: 0.8780\n",
      "Epoch 195/3000\n",
      " - 0s - loss: 0.2857 - mean_squared_error: 0.0842 - acc: 0.8876 - val_loss: 0.2952 - val_mean_squared_error: 0.0898 - val_acc: 0.8780\n",
      "Epoch 196/3000\n",
      " - 0s - loss: 0.2841 - mean_squared_error: 0.0840 - acc: 0.8922 - val_loss: 0.2952 - val_mean_squared_error: 0.0898 - val_acc: 0.8780\n",
      "Epoch 197/3000\n",
      " - 0s - loss: 0.2833 - mean_squared_error: 0.0837 - acc: 0.8911 - val_loss: 0.2951 - val_mean_squared_error: 0.0898 - val_acc: 0.8780\n",
      "Epoch 198/3000\n",
      " - 0s - loss: 0.2838 - mean_squared_error: 0.0837 - acc: 0.8934 - val_loss: 0.2950 - val_mean_squared_error: 0.0898 - val_acc: 0.8815\n",
      "Epoch 199/3000\n",
      " - 0s - loss: 0.2843 - mean_squared_error: 0.0839 - acc: 0.8911 - val_loss: 0.2948 - val_mean_squared_error: 0.0898 - val_acc: 0.8815\n",
      "Epoch 200/3000\n",
      " - 0s - loss: 0.2850 - mean_squared_error: 0.0843 - acc: 0.8830 - val_loss: 0.2946 - val_mean_squared_error: 0.0897 - val_acc: 0.8815\n",
      "Epoch 201/3000\n",
      " - 0s - loss: 0.2835 - mean_squared_error: 0.0834 - acc: 0.8922 - val_loss: 0.2944 - val_mean_squared_error: 0.0897 - val_acc: 0.8815\n",
      "Epoch 202/3000\n",
      " - 0s - loss: 0.2828 - mean_squared_error: 0.0832 - acc: 0.8922 - val_loss: 0.2941 - val_mean_squared_error: 0.0896 - val_acc: 0.8815\n",
      "Epoch 203/3000\n",
      " - 0s - loss: 0.2834 - mean_squared_error: 0.0838 - acc: 0.8888 - val_loss: 0.2937 - val_mean_squared_error: 0.0896 - val_acc: 0.8815\n",
      "Epoch 204/3000\n",
      " - 0s - loss: 0.2831 - mean_squared_error: 0.0833 - acc: 0.8888 - val_loss: 0.2934 - val_mean_squared_error: 0.0895 - val_acc: 0.8780\n",
      "Epoch 205/3000\n",
      " - 0s - loss: 0.2814 - mean_squared_error: 0.0831 - acc: 0.8934 - val_loss: 0.2931 - val_mean_squared_error: 0.0895 - val_acc: 0.8780\n",
      "Epoch 206/3000\n",
      " - 0s - loss: 0.2863 - mean_squared_error: 0.0848 - acc: 0.8922 - val_loss: 0.2929 - val_mean_squared_error: 0.0894 - val_acc: 0.8780\n",
      "Epoch 207/3000\n",
      " - 0s - loss: 0.2798 - mean_squared_error: 0.0826 - acc: 0.8922 - val_loss: 0.2928 - val_mean_squared_error: 0.0894 - val_acc: 0.8780\n",
      "Epoch 208/3000\n",
      " - 0s - loss: 0.2788 - mean_squared_error: 0.0824 - acc: 0.8946 - val_loss: 0.2927 - val_mean_squared_error: 0.0894 - val_acc: 0.8746\n",
      "Epoch 209/3000\n",
      " - 0s - loss: 0.2805 - mean_squared_error: 0.0828 - acc: 0.8876 - val_loss: 0.2926 - val_mean_squared_error: 0.0894 - val_acc: 0.8746\n",
      "Epoch 210/3000\n",
      " - 0s - loss: 0.2803 - mean_squared_error: 0.0829 - acc: 0.8888 - val_loss: 0.2925 - val_mean_squared_error: 0.0894 - val_acc: 0.8746\n",
      "Epoch 211/3000\n",
      " - 0s - loss: 0.2797 - mean_squared_error: 0.0830 - acc: 0.8946 - val_loss: 0.2925 - val_mean_squared_error: 0.0894 - val_acc: 0.8746\n",
      "Epoch 212/3000\n",
      " - 0s - loss: 0.2795 - mean_squared_error: 0.0822 - acc: 0.8876 - val_loss: 0.2924 - val_mean_squared_error: 0.0894 - val_acc: 0.8746\n",
      "Epoch 213/3000\n",
      " - 0s - loss: 0.2790 - mean_squared_error: 0.0824 - acc: 0.8899 - val_loss: 0.2923 - val_mean_squared_error: 0.0893 - val_acc: 0.8746\n",
      "Epoch 214/3000\n",
      " - 0s - loss: 0.2806 - mean_squared_error: 0.0828 - acc: 0.8899 - val_loss: 0.2922 - val_mean_squared_error: 0.0893 - val_acc: 0.8780\n",
      "Epoch 215/3000\n",
      " - 0s - loss: 0.2787 - mean_squared_error: 0.0823 - acc: 0.8922 - val_loss: 0.2921 - val_mean_squared_error: 0.0893 - val_acc: 0.8780\n",
      "Epoch 216/3000\n",
      " - 0s - loss: 0.2803 - mean_squared_error: 0.0825 - acc: 0.8934 - val_loss: 0.2919 - val_mean_squared_error: 0.0893 - val_acc: 0.8780\n",
      "Epoch 217/3000\n",
      " - 0s - loss: 0.2785 - mean_squared_error: 0.0822 - acc: 0.8911 - val_loss: 0.2917 - val_mean_squared_error: 0.0892 - val_acc: 0.8780\n",
      "Epoch 218/3000\n",
      " - 0s - loss: 0.2791 - mean_squared_error: 0.0826 - acc: 0.8969 - val_loss: 0.2914 - val_mean_squared_error: 0.0892 - val_acc: 0.8780\n",
      "Epoch 219/3000\n",
      " - 0s - loss: 0.2796 - mean_squared_error: 0.0825 - acc: 0.8957 - val_loss: 0.2912 - val_mean_squared_error: 0.0892 - val_acc: 0.8780\n",
      "Epoch 220/3000\n",
      " - 0s - loss: 0.2780 - mean_squared_error: 0.0824 - acc: 0.8899 - val_loss: 0.2910 - val_mean_squared_error: 0.0891 - val_acc: 0.8746\n",
      "Epoch 221/3000\n",
      " - 0s - loss: 0.2755 - mean_squared_error: 0.0812 - acc: 0.8888 - val_loss: 0.2908 - val_mean_squared_error: 0.0891 - val_acc: 0.8746\n",
      "Epoch 222/3000\n",
      " - 0s - loss: 0.2768 - mean_squared_error: 0.0816 - acc: 0.8934 - val_loss: 0.2907 - val_mean_squared_error: 0.0891 - val_acc: 0.8746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/3000\n",
      " - 0s - loss: 0.2773 - mean_squared_error: 0.0820 - acc: 0.8946 - val_loss: 0.2906 - val_mean_squared_error: 0.0891 - val_acc: 0.8746\n",
      "Epoch 224/3000\n",
      " - 0s - loss: 0.2762 - mean_squared_error: 0.0814 - acc: 0.8888 - val_loss: 0.2905 - val_mean_squared_error: 0.0890 - val_acc: 0.8746\n",
      "Epoch 225/3000\n",
      " - 0s - loss: 0.2752 - mean_squared_error: 0.0816 - acc: 0.8876 - val_loss: 0.2905 - val_mean_squared_error: 0.0890 - val_acc: 0.8746\n",
      "Epoch 226/3000\n",
      " - 0s - loss: 0.2765 - mean_squared_error: 0.0812 - acc: 0.8957 - val_loss: 0.2904 - val_mean_squared_error: 0.0890 - val_acc: 0.8746\n",
      "Epoch 227/3000\n",
      " - 0s - loss: 0.2777 - mean_squared_error: 0.0820 - acc: 0.8922 - val_loss: 0.2904 - val_mean_squared_error: 0.0890 - val_acc: 0.8746\n",
      "Epoch 228/3000\n",
      " - 0s - loss: 0.2770 - mean_squared_error: 0.0819 - acc: 0.8911 - val_loss: 0.2903 - val_mean_squared_error: 0.0890 - val_acc: 0.8711\n",
      "Epoch 229/3000\n",
      " - 0s - loss: 0.2728 - mean_squared_error: 0.0802 - acc: 0.8934 - val_loss: 0.2902 - val_mean_squared_error: 0.0890 - val_acc: 0.8746\n",
      "Epoch 230/3000\n",
      " - 0s - loss: 0.2706 - mean_squared_error: 0.0795 - acc: 0.8911 - val_loss: 0.2901 - val_mean_squared_error: 0.0890 - val_acc: 0.8746\n",
      "Epoch 231/3000\n",
      " - 0s - loss: 0.2751 - mean_squared_error: 0.0810 - acc: 0.8888 - val_loss: 0.2899 - val_mean_squared_error: 0.0889 - val_acc: 0.8746\n",
      "Epoch 232/3000\n",
      " - 0s - loss: 0.2715 - mean_squared_error: 0.0802 - acc: 0.8934 - val_loss: 0.2897 - val_mean_squared_error: 0.0889 - val_acc: 0.8746\n",
      "Epoch 233/3000\n",
      " - 0s - loss: 0.2722 - mean_squared_error: 0.0803 - acc: 0.8934 - val_loss: 0.2895 - val_mean_squared_error: 0.0889 - val_acc: 0.8746\n",
      "Epoch 234/3000\n",
      " - 0s - loss: 0.2736 - mean_squared_error: 0.0805 - acc: 0.8911 - val_loss: 0.2894 - val_mean_squared_error: 0.0889 - val_acc: 0.8746\n",
      "Epoch 235/3000\n",
      " - 0s - loss: 0.2745 - mean_squared_error: 0.0808 - acc: 0.8911 - val_loss: 0.2893 - val_mean_squared_error: 0.0888 - val_acc: 0.8746\n",
      "Epoch 236/3000\n",
      " - 0s - loss: 0.2704 - mean_squared_error: 0.0794 - acc: 0.8946 - val_loss: 0.2892 - val_mean_squared_error: 0.0888 - val_acc: 0.8746\n",
      "Epoch 237/3000\n",
      " - 0s - loss: 0.2718 - mean_squared_error: 0.0802 - acc: 0.8899 - val_loss: 0.2891 - val_mean_squared_error: 0.0888 - val_acc: 0.8746\n",
      "Epoch 238/3000\n",
      " - 0s - loss: 0.2729 - mean_squared_error: 0.0806 - acc: 0.8934 - val_loss: 0.2890 - val_mean_squared_error: 0.0888 - val_acc: 0.8746\n",
      "Epoch 239/3000\n",
      " - 0s - loss: 0.2713 - mean_squared_error: 0.0797 - acc: 0.8934 - val_loss: 0.2889 - val_mean_squared_error: 0.0888 - val_acc: 0.8746\n",
      "Epoch 240/3000\n",
      " - 0s - loss: 0.2719 - mean_squared_error: 0.0801 - acc: 0.8969 - val_loss: 0.2889 - val_mean_squared_error: 0.0888 - val_acc: 0.8746\n",
      "Epoch 241/3000\n",
      " - 0s - loss: 0.2704 - mean_squared_error: 0.0798 - acc: 0.8911 - val_loss: 0.2889 - val_mean_squared_error: 0.0888 - val_acc: 0.8746\n",
      "Epoch 242/3000\n",
      " - 0s - loss: 0.2710 - mean_squared_error: 0.0797 - acc: 0.8922 - val_loss: 0.2889 - val_mean_squared_error: 0.0888 - val_acc: 0.8711\n",
      "Epoch 243/3000\n",
      " - 0s - loss: 0.2709 - mean_squared_error: 0.0796 - acc: 0.8899 - val_loss: 0.2888 - val_mean_squared_error: 0.0888 - val_acc: 0.8711\n",
      "Epoch 244/3000\n",
      " - 0s - loss: 0.2714 - mean_squared_error: 0.0802 - acc: 0.8911 - val_loss: 0.2887 - val_mean_squared_error: 0.0888 - val_acc: 0.8711\n",
      "Epoch 245/3000\n",
      " - 0s - loss: 0.2661 - mean_squared_error: 0.0785 - acc: 0.8957 - val_loss: 0.2886 - val_mean_squared_error: 0.0887 - val_acc: 0.8676\n",
      "Epoch 246/3000\n",
      " - 0s - loss: 0.2709 - mean_squared_error: 0.0802 - acc: 0.8922 - val_loss: 0.2884 - val_mean_squared_error: 0.0887 - val_acc: 0.8676\n",
      "Epoch 247/3000\n",
      " - 0s - loss: 0.2701 - mean_squared_error: 0.0793 - acc: 0.8934 - val_loss: 0.2882 - val_mean_squared_error: 0.0887 - val_acc: 0.8676\n",
      "Epoch 248/3000\n",
      " - 0s - loss: 0.2683 - mean_squared_error: 0.0791 - acc: 0.8946 - val_loss: 0.2880 - val_mean_squared_error: 0.0886 - val_acc: 0.8676\n",
      "Epoch 249/3000\n",
      " - 0s - loss: 0.2683 - mean_squared_error: 0.0791 - acc: 0.8946 - val_loss: 0.2878 - val_mean_squared_error: 0.0886 - val_acc: 0.8676\n",
      "Epoch 250/3000\n",
      " - 0s - loss: 0.2690 - mean_squared_error: 0.0791 - acc: 0.8957 - val_loss: 0.2876 - val_mean_squared_error: 0.0886 - val_acc: 0.8676\n",
      "Epoch 251/3000\n",
      " - 0s - loss: 0.2689 - mean_squared_error: 0.0792 - acc: 0.8946 - val_loss: 0.2875 - val_mean_squared_error: 0.0886 - val_acc: 0.8676\n",
      "Epoch 252/3000\n",
      " - 0s - loss: 0.2673 - mean_squared_error: 0.0786 - acc: 0.8957 - val_loss: 0.2874 - val_mean_squared_error: 0.0886 - val_acc: 0.8676\n",
      "Epoch 253/3000\n",
      " - 0s - loss: 0.2661 - mean_squared_error: 0.0783 - acc: 0.8969 - val_loss: 0.2874 - val_mean_squared_error: 0.0886 - val_acc: 0.8676\n",
      "Epoch 254/3000\n",
      " - 0s - loss: 0.2671 - mean_squared_error: 0.0783 - acc: 0.8992 - val_loss: 0.2874 - val_mean_squared_error: 0.0886 - val_acc: 0.8676\n",
      "Epoch 255/3000\n",
      " - 0s - loss: 0.2695 - mean_squared_error: 0.0796 - acc: 0.8957 - val_loss: 0.2873 - val_mean_squared_error: 0.0886 - val_acc: 0.8676\n",
      "Epoch 256/3000\n",
      " - 0s - loss: 0.2674 - mean_squared_error: 0.0788 - acc: 0.8957 - val_loss: 0.2873 - val_mean_squared_error: 0.0886 - val_acc: 0.8676\n",
      "Epoch 257/3000\n",
      " - 0s - loss: 0.2683 - mean_squared_error: 0.0790 - acc: 0.8922 - val_loss: 0.2873 - val_mean_squared_error: 0.0886 - val_acc: 0.8676\n",
      "Epoch 258/3000\n",
      " - 0s - loss: 0.2654 - mean_squared_error: 0.0779 - acc: 0.8946 - val_loss: 0.2872 - val_mean_squared_error: 0.0886 - val_acc: 0.8676\n",
      "Epoch 259/3000\n",
      " - 0s - loss: 0.2683 - mean_squared_error: 0.0790 - acc: 0.8957 - val_loss: 0.2871 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 260/3000\n",
      " - 0s - loss: 0.2675 - mean_squared_error: 0.0786 - acc: 0.8957 - val_loss: 0.2870 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 261/3000\n",
      " - 0s - loss: 0.2666 - mean_squared_error: 0.0788 - acc: 0.8922 - val_loss: 0.2869 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 262/3000\n",
      " - 0s - loss: 0.2651 - mean_squared_error: 0.0782 - acc: 0.8934 - val_loss: 0.2868 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 263/3000\n",
      " - 0s - loss: 0.2642 - mean_squared_error: 0.0779 - acc: 0.9003 - val_loss: 0.2866 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 264/3000\n",
      " - 0s - loss: 0.2653 - mean_squared_error: 0.0782 - acc: 0.8957 - val_loss: 0.2865 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 265/3000\n",
      " - 0s - loss: 0.2642 - mean_squared_error: 0.0777 - acc: 0.8957 - val_loss: 0.2865 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 266/3000\n",
      " - 0s - loss: 0.2638 - mean_squared_error: 0.0775 - acc: 0.9003 - val_loss: 0.2864 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 267/3000\n",
      " - 0s - loss: 0.2624 - mean_squared_error: 0.0772 - acc: 0.8969 - val_loss: 0.2864 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 268/3000\n",
      " - 0s - loss: 0.2668 - mean_squared_error: 0.0787 - acc: 0.8969 - val_loss: 0.2864 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 269/3000\n",
      " - 0s - loss: 0.2643 - mean_squared_error: 0.0778 - acc: 0.8934 - val_loss: 0.2863 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 270/3000\n",
      " - 0s - loss: 0.2645 - mean_squared_error: 0.0780 - acc: 0.8957 - val_loss: 0.2863 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 271/3000\n",
      " - 0s - loss: 0.2606 - mean_squared_error: 0.0766 - acc: 0.8992 - val_loss: 0.2863 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 272/3000\n",
      " - 0s - loss: 0.2641 - mean_squared_error: 0.0781 - acc: 0.8946 - val_loss: 0.2863 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 273/3000\n",
      " - 0s - loss: 0.2635 - mean_squared_error: 0.0778 - acc: 0.8980 - val_loss: 0.2863 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 274/3000\n",
      " - 0s - loss: 0.2639 - mean_squared_error: 0.0776 - acc: 0.8980 - val_loss: 0.2862 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 275/3000\n",
      " - 0s - loss: 0.2613 - mean_squared_error: 0.0768 - acc: 0.9038 - val_loss: 0.2862 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n",
      "Epoch 276/3000\n",
      " - 0s - loss: 0.2622 - mean_squared_error: 0.0771 - acc: 0.9003 - val_loss: 0.2862 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 277/3000\n",
      " - 0s - loss: 0.2619 - mean_squared_error: 0.0771 - acc: 0.8980 - val_loss: 0.2861 - val_mean_squared_error: 0.0885 - val_acc: 0.8676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/3000\n",
      " - 0s - loss: 0.2609 - mean_squared_error: 0.0768 - acc: 0.8969 - val_loss: 0.2860 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 279/3000\n",
      " - 0s - loss: 0.2622 - mean_squared_error: 0.0771 - acc: 0.9003 - val_loss: 0.2859 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 280/3000\n",
      " - 0s - loss: 0.2581 - mean_squared_error: 0.0761 - acc: 0.8992 - val_loss: 0.2858 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 281/3000\n",
      " - 0s - loss: 0.2598 - mean_squared_error: 0.0761 - acc: 0.9038 - val_loss: 0.2857 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 282/3000\n",
      " - 0s - loss: 0.2596 - mean_squared_error: 0.0761 - acc: 0.9050 - val_loss: 0.2857 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 283/3000\n",
      " - 0s - loss: 0.2585 - mean_squared_error: 0.0762 - acc: 0.9015 - val_loss: 0.2856 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 284/3000\n",
      " - 0s - loss: 0.2588 - mean_squared_error: 0.0761 - acc: 0.8957 - val_loss: 0.2856 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 285/3000\n",
      " - 0s - loss: 0.2622 - mean_squared_error: 0.0773 - acc: 0.8992 - val_loss: 0.2855 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 286/3000\n",
      " - 0s - loss: 0.2559 - mean_squared_error: 0.0749 - acc: 0.9038 - val_loss: 0.2855 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 287/3000\n",
      " - 0s - loss: 0.2612 - mean_squared_error: 0.0769 - acc: 0.9027 - val_loss: 0.2855 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 288/3000\n",
      " - 0s - loss: 0.2572 - mean_squared_error: 0.0757 - acc: 0.9015 - val_loss: 0.2855 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 289/3000\n",
      " - 0s - loss: 0.2591 - mean_squared_error: 0.0762 - acc: 0.8969 - val_loss: 0.2854 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 290/3000\n",
      " - 0s - loss: 0.2607 - mean_squared_error: 0.0773 - acc: 0.8992 - val_loss: 0.2854 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 291/3000\n",
      " - 0s - loss: 0.2583 - mean_squared_error: 0.0760 - acc: 0.9027 - val_loss: 0.2853 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 292/3000\n",
      " - 0s - loss: 0.2585 - mean_squared_error: 0.0759 - acc: 0.9003 - val_loss: 0.2852 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 293/3000\n",
      " - 0s - loss: 0.2600 - mean_squared_error: 0.0766 - acc: 0.8911 - val_loss: 0.2852 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 294/3000\n",
      " - 0s - loss: 0.2582 - mean_squared_error: 0.0757 - acc: 0.8992 - val_loss: 0.2852 - val_mean_squared_error: 0.0884 - val_acc: 0.8676\n",
      "Epoch 295/3000\n",
      " - 0s - loss: 0.2555 - mean_squared_error: 0.0753 - acc: 0.9015 - val_loss: 0.2851 - val_mean_squared_error: 0.0883 - val_acc: 0.8676\n",
      "Epoch 296/3000\n",
      " - 0s - loss: 0.2568 - mean_squared_error: 0.0754 - acc: 0.8992 - val_loss: 0.2851 - val_mean_squared_error: 0.0883 - val_acc: 0.8641\n",
      "Epoch 297/3000\n",
      " - 0s - loss: 0.2573 - mean_squared_error: 0.0758 - acc: 0.8980 - val_loss: 0.2850 - val_mean_squared_error: 0.0883 - val_acc: 0.8641\n",
      "Epoch 298/3000\n",
      " - 0s - loss: 0.2528 - mean_squared_error: 0.0743 - acc: 0.9015 - val_loss: 0.2850 - val_mean_squared_error: 0.0883 - val_acc: 0.8641\n",
      "Epoch 299/3000\n",
      " - 0s - loss: 0.2544 - mean_squared_error: 0.0747 - acc: 0.9015 - val_loss: 0.2850 - val_mean_squared_error: 0.0883 - val_acc: 0.8641\n",
      "Epoch 300/3000\n",
      " - 0s - loss: 0.2571 - mean_squared_error: 0.0762 - acc: 0.8957 - val_loss: 0.2850 - val_mean_squared_error: 0.0883 - val_acc: 0.8641\n",
      "Epoch 301/3000\n",
      " - 0s - loss: 0.2519 - mean_squared_error: 0.0739 - acc: 0.9050 - val_loss: 0.2850 - val_mean_squared_error: 0.0883 - val_acc: 0.8641\n",
      "Epoch 302/3000\n",
      " - 0s - loss: 0.2561 - mean_squared_error: 0.0751 - acc: 0.9003 - val_loss: 0.2849 - val_mean_squared_error: 0.0883 - val_acc: 0.8641\n",
      "Epoch 303/3000\n",
      " - 0s - loss: 0.2528 - mean_squared_error: 0.0745 - acc: 0.8980 - val_loss: 0.2849 - val_mean_squared_error: 0.0883 - val_acc: 0.8641\n",
      "Epoch 304/3000\n",
      " - 0s - loss: 0.2554 - mean_squared_error: 0.0751 - acc: 0.9015 - val_loss: 0.2849 - val_mean_squared_error: 0.0883 - val_acc: 0.8641\n",
      "Epoch 305/3000\n",
      " - 0s - loss: 0.2563 - mean_squared_error: 0.0756 - acc: 0.9015 - val_loss: 0.2849 - val_mean_squared_error: 0.0883 - val_acc: 0.8641\n",
      "Epoch 306/3000\n",
      " - 0s - loss: 0.2575 - mean_squared_error: 0.0763 - acc: 0.8969 - val_loss: 0.2849 - val_mean_squared_error: 0.0883 - val_acc: 0.8641\n",
      "Epoch 307/3000\n",
      " - 0s - loss: 0.2499 - mean_squared_error: 0.0730 - acc: 0.9038 - val_loss: 0.2849 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 308/3000\n",
      " - 0s - loss: 0.2529 - mean_squared_error: 0.0747 - acc: 0.9015 - val_loss: 0.2849 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 309/3000\n",
      " - 0s - loss: 0.2533 - mean_squared_error: 0.0744 - acc: 0.9038 - val_loss: 0.2849 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 310/3000\n",
      " - 0s - loss: 0.2511 - mean_squared_error: 0.0734 - acc: 0.9061 - val_loss: 0.2849 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 311/3000\n",
      " - 0s - loss: 0.2529 - mean_squared_error: 0.0743 - acc: 0.9038 - val_loss: 0.2848 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 312/3000\n",
      " - 0s - loss: 0.2536 - mean_squared_error: 0.0746 - acc: 0.9061 - val_loss: 0.2848 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 313/3000\n",
      " - 0s - loss: 0.2544 - mean_squared_error: 0.0751 - acc: 0.9038 - val_loss: 0.2847 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 314/3000\n",
      " - 0s - loss: 0.2501 - mean_squared_error: 0.0733 - acc: 0.9073 - val_loss: 0.2847 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 315/3000\n",
      " - 0s - loss: 0.2529 - mean_squared_error: 0.0745 - acc: 0.9061 - val_loss: 0.2847 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 316/3000\n",
      " - 0s - loss: 0.2498 - mean_squared_error: 0.0730 - acc: 0.9015 - val_loss: 0.2847 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 317/3000\n",
      " - 0s - loss: 0.2522 - mean_squared_error: 0.0736 - acc: 0.9096 - val_loss: 0.2847 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 318/3000\n",
      " - 0s - loss: 0.2508 - mean_squared_error: 0.0738 - acc: 0.9015 - val_loss: 0.2847 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 319/3000\n",
      " - 0s - loss: 0.2504 - mean_squared_error: 0.0734 - acc: 0.8992 - val_loss: 0.2846 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 320/3000\n",
      " - 0s - loss: 0.2514 - mean_squared_error: 0.0736 - acc: 0.9038 - val_loss: 0.2846 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 321/3000\n",
      " - 0s - loss: 0.2512 - mean_squared_error: 0.0740 - acc: 0.8992 - val_loss: 0.2846 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 322/3000\n",
      " - 0s - loss: 0.2525 - mean_squared_error: 0.0742 - acc: 0.9061 - val_loss: 0.2845 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 323/3000\n",
      " - 0s - loss: 0.2499 - mean_squared_error: 0.0734 - acc: 0.9061 - val_loss: 0.2845 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 324/3000\n",
      " - 0s - loss: 0.2495 - mean_squared_error: 0.0734 - acc: 0.9050 - val_loss: 0.2845 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 325/3000\n",
      " - 0s - loss: 0.2479 - mean_squared_error: 0.0728 - acc: 0.9015 - val_loss: 0.2845 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 326/3000\n",
      " - 0s - loss: 0.2492 - mean_squared_error: 0.0733 - acc: 0.9038 - val_loss: 0.2844 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 327/3000\n",
      " - 0s - loss: 0.2479 - mean_squared_error: 0.0728 - acc: 0.9085 - val_loss: 0.2844 - val_mean_squared_error: 0.0885 - val_acc: 0.8641\n",
      "Epoch 328/3000\n",
      " - 0s - loss: 0.2519 - mean_squared_error: 0.0739 - acc: 0.9027 - val_loss: 0.2844 - val_mean_squared_error: 0.0885 - val_acc: 0.8641\n",
      "Epoch 329/3000\n",
      " - 0s - loss: 0.2504 - mean_squared_error: 0.0740 - acc: 0.8969 - val_loss: 0.2844 - val_mean_squared_error: 0.0885 - val_acc: 0.8641\n",
      "Epoch 330/3000\n",
      " - 0s - loss: 0.2493 - mean_squared_error: 0.0733 - acc: 0.9050 - val_loss: 0.2844 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 331/3000\n",
      " - 0s - loss: 0.2465 - mean_squared_error: 0.0723 - acc: 0.9061 - val_loss: 0.2844 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 332/3000\n",
      " - 0s - loss: 0.2487 - mean_squared_error: 0.0734 - acc: 0.9038 - val_loss: 0.2843 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/3000\n",
      " - 0s - loss: 0.2495 - mean_squared_error: 0.0735 - acc: 0.9050 - val_loss: 0.2843 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 334/3000\n",
      " - 0s - loss: 0.2459 - mean_squared_error: 0.0719 - acc: 0.9050 - val_loss: 0.2843 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 335/3000\n",
      " - 0s - loss: 0.2479 - mean_squared_error: 0.0726 - acc: 0.9050 - val_loss: 0.2842 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 336/3000\n",
      " - 0s - loss: 0.2503 - mean_squared_error: 0.0735 - acc: 0.9038 - val_loss: 0.2841 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 337/3000\n",
      " - 0s - loss: 0.2475 - mean_squared_error: 0.0729 - acc: 0.8992 - val_loss: 0.2841 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 338/3000\n",
      " - 0s - loss: 0.2484 - mean_squared_error: 0.0733 - acc: 0.9015 - val_loss: 0.2841 - val_mean_squared_error: 0.0884 - val_acc: 0.8641\n",
      "Epoch 339/3000\n",
      " - 0s - loss: 0.2485 - mean_squared_error: 0.0727 - acc: 0.9096 - val_loss: 0.2840 - val_mean_squared_error: 0.0884 - val_acc: 0.8571\n",
      "Epoch 340/3000\n",
      " - 0s - loss: 0.2468 - mean_squared_error: 0.0726 - acc: 0.9038 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8606\n",
      "Epoch 341/3000\n",
      " - 0s - loss: 0.2474 - mean_squared_error: 0.0725 - acc: 0.9131 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8606\n",
      "Epoch 342/3000\n",
      " - 0s - loss: 0.2477 - mean_squared_error: 0.0728 - acc: 0.9038 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8606\n",
      "Epoch 343/3000\n",
      " - 0s - loss: 0.2485 - mean_squared_error: 0.0729 - acc: 0.9096 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8606\n",
      "Epoch 344/3000\n",
      " - 0s - loss: 0.2432 - mean_squared_error: 0.0713 - acc: 0.9061 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8606\n",
      "Epoch 345/3000\n",
      " - 0s - loss: 0.2444 - mean_squared_error: 0.0714 - acc: 0.9096 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8606\n",
      "Epoch 346/3000\n",
      " - 0s - loss: 0.2426 - mean_squared_error: 0.0707 - acc: 0.9085 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8606\n",
      "Epoch 347/3000\n",
      " - 0s - loss: 0.2462 - mean_squared_error: 0.0720 - acc: 0.9061 - val_loss: 0.2840 - val_mean_squared_error: 0.0885 - val_acc: 0.8606\n",
      "Epoch 348/3000\n",
      " - 0s - loss: 0.2441 - mean_squared_error: 0.0718 - acc: 0.9061 - val_loss: 0.2840 - val_mean_squared_error: 0.0885 - val_acc: 0.8606\n",
      "Epoch 349/3000\n",
      " - 0s - loss: 0.2437 - mean_squared_error: 0.0713 - acc: 0.9096 - val_loss: 0.2840 - val_mean_squared_error: 0.0884 - val_acc: 0.8606\n",
      "Epoch 350/3000\n",
      " - 0s - loss: 0.2458 - mean_squared_error: 0.0719 - acc: 0.9096 - val_loss: 0.2840 - val_mean_squared_error: 0.0884 - val_acc: 0.8606\n",
      "Epoch 351/3000\n",
      " - 0s - loss: 0.2443 - mean_squared_error: 0.0717 - acc: 0.9038 - val_loss: 0.2840 - val_mean_squared_error: 0.0885 - val_acc: 0.8606\n",
      "Epoch 352/3000\n",
      " - 0s - loss: 0.2457 - mean_squared_error: 0.0721 - acc: 0.9050 - val_loss: 0.2840 - val_mean_squared_error: 0.0885 - val_acc: 0.8606\n",
      "Epoch 353/3000\n",
      " - 0s - loss: 0.2461 - mean_squared_error: 0.0724 - acc: 0.9073 - val_loss: 0.2840 - val_mean_squared_error: 0.0885 - val_acc: 0.8571\n",
      "Epoch 354/3000\n",
      " - 0s - loss: 0.2451 - mean_squared_error: 0.0719 - acc: 0.9050 - val_loss: 0.2840 - val_mean_squared_error: 0.0885 - val_acc: 0.8571\n",
      "Epoch 355/3000\n",
      " - 0s - loss: 0.2418 - mean_squared_error: 0.0706 - acc: 0.9096 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8571\n",
      "Epoch 356/3000\n",
      " - 0s - loss: 0.2427 - mean_squared_error: 0.0712 - acc: 0.9143 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8571\n",
      "Epoch 357/3000\n",
      " - 0s - loss: 0.2411 - mean_squared_error: 0.0705 - acc: 0.9119 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8571\n",
      "Epoch 358/3000\n",
      " - 0s - loss: 0.2439 - mean_squared_error: 0.0714 - acc: 0.9038 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8571\n",
      "Epoch 359/3000\n",
      " - 0s - loss: 0.2419 - mean_squared_error: 0.0709 - acc: 0.9061 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8571\n",
      "Epoch 360/3000\n",
      " - 0s - loss: 0.2408 - mean_squared_error: 0.0705 - acc: 0.9108 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8571\n",
      "Epoch 361/3000\n",
      " - 0s - loss: 0.2430 - mean_squared_error: 0.0714 - acc: 0.9085 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8571\n",
      "Epoch 362/3000\n",
      " - 0s - loss: 0.2411 - mean_squared_error: 0.0711 - acc: 0.9085 - val_loss: 0.2841 - val_mean_squared_error: 0.0885 - val_acc: 0.8571\n",
      "Epoch 363/3000\n",
      " - 0s - loss: 0.2429 - mean_squared_error: 0.0713 - acc: 0.9096 - val_loss: 0.2842 - val_mean_squared_error: 0.0885 - val_acc: 0.8571\n",
      "Epoch 364/3000\n",
      " - 0s - loss: 0.2419 - mean_squared_error: 0.0709 - acc: 0.9061 - val_loss: 0.2842 - val_mean_squared_error: 0.0885 - val_acc: 0.8606\n",
      "Epoch 365/3000\n",
      " - 0s - loss: 0.2413 - mean_squared_error: 0.0705 - acc: 0.9108 - val_loss: 0.2842 - val_mean_squared_error: 0.0885 - val_acc: 0.8606\n",
      "Epoch 366/3000\n",
      " - 0s - loss: 0.2412 - mean_squared_error: 0.0705 - acc: 0.9085 - val_loss: 0.2843 - val_mean_squared_error: 0.0886 - val_acc: 0.8606\n",
      "Epoch 367/3000\n",
      " - 0s - loss: 0.2424 - mean_squared_error: 0.0708 - acc: 0.9085 - val_loss: 0.2843 - val_mean_squared_error: 0.0886 - val_acc: 0.8606\n",
      "Epoch 368/3000\n",
      " - 0s - loss: 0.2402 - mean_squared_error: 0.0705 - acc: 0.9096 - val_loss: 0.2844 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 369/3000\n",
      " - 0s - loss: 0.2410 - mean_squared_error: 0.0703 - acc: 0.9131 - val_loss: 0.2844 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 370/3000\n",
      " - 0s - loss: 0.2402 - mean_squared_error: 0.0704 - acc: 0.9119 - val_loss: 0.2844 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 371/3000\n",
      " - 0s - loss: 0.2405 - mean_squared_error: 0.0705 - acc: 0.9108 - val_loss: 0.2844 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 372/3000\n",
      " - 0s - loss: 0.2370 - mean_squared_error: 0.0691 - acc: 0.9108 - val_loss: 0.2843 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 373/3000\n",
      " - 0s - loss: 0.2366 - mean_squared_error: 0.0693 - acc: 0.9119 - val_loss: 0.2843 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 374/3000\n",
      " - 0s - loss: 0.2383 - mean_squared_error: 0.0699 - acc: 0.9096 - val_loss: 0.2842 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 375/3000\n",
      " - 0s - loss: 0.2419 - mean_squared_error: 0.0707 - acc: 0.9108 - val_loss: 0.2842 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 376/3000\n",
      " - 0s - loss: 0.2416 - mean_squared_error: 0.0706 - acc: 0.9131 - val_loss: 0.2842 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 377/3000\n",
      " - 0s - loss: 0.2399 - mean_squared_error: 0.0703 - acc: 0.9096 - val_loss: 0.2842 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 378/3000\n",
      " - 0s - loss: 0.2349 - mean_squared_error: 0.0684 - acc: 0.9096 - val_loss: 0.2842 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 379/3000\n",
      " - 0s - loss: 0.2393 - mean_squared_error: 0.0698 - acc: 0.9108 - val_loss: 0.2842 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 380/3000\n",
      " - 0s - loss: 0.2406 - mean_squared_error: 0.0707 - acc: 0.9119 - val_loss: 0.2842 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 381/3000\n",
      " - 0s - loss: 0.2400 - mean_squared_error: 0.0705 - acc: 0.9027 - val_loss: 0.2842 - val_mean_squared_error: 0.0886 - val_acc: 0.8606\n",
      "Epoch 382/3000\n",
      " - 0s - loss: 0.2401 - mean_squared_error: 0.0703 - acc: 0.9061 - val_loss: 0.2842 - val_mean_squared_error: 0.0886 - val_acc: 0.8606\n",
      "Epoch 383/3000\n",
      " - 0s - loss: 0.2386 - mean_squared_error: 0.0698 - acc: 0.9108 - val_loss: 0.2842 - val_mean_squared_error: 0.0886 - val_acc: 0.8606\n",
      "Epoch 384/3000\n",
      " - 0s - loss: 0.2366 - mean_squared_error: 0.0690 - acc: 0.9166 - val_loss: 0.2843 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 385/3000\n",
      " - 0s - loss: 0.2368 - mean_squared_error: 0.0691 - acc: 0.9166 - val_loss: 0.2843 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 386/3000\n",
      " - 0s - loss: 0.2385 - mean_squared_error: 0.0698 - acc: 0.9096 - val_loss: 0.2843 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 387/3000\n",
      " - 0s - loss: 0.2368 - mean_squared_error: 0.0691 - acc: 0.9119 - val_loss: 0.2844 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/3000\n",
      " - 0s - loss: 0.2374 - mean_squared_error: 0.0697 - acc: 0.9131 - val_loss: 0.2844 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 389/3000\n",
      " - 0s - loss: 0.2370 - mean_squared_error: 0.0692 - acc: 0.9085 - val_loss: 0.2844 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 390/3000\n",
      " - 0s - loss: 0.2361 - mean_squared_error: 0.0690 - acc: 0.9119 - val_loss: 0.2844 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 391/3000\n",
      " - 0s - loss: 0.2356 - mean_squared_error: 0.0690 - acc: 0.9119 - val_loss: 0.2844 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 392/3000\n",
      " - 0s - loss: 0.2343 - mean_squared_error: 0.0688 - acc: 0.9085 - val_loss: 0.2845 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 393/3000\n",
      " - 0s - loss: 0.2399 - mean_squared_error: 0.0707 - acc: 0.9085 - val_loss: 0.2845 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 394/3000\n",
      " - 0s - loss: 0.2348 - mean_squared_error: 0.0691 - acc: 0.9096 - val_loss: 0.2845 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 395/3000\n",
      " - 0s - loss: 0.2383 - mean_squared_error: 0.0699 - acc: 0.9108 - val_loss: 0.2845 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 396/3000\n",
      " - 0s - loss: 0.2336 - mean_squared_error: 0.0679 - acc: 0.9108 - val_loss: 0.2845 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 397/3000\n",
      " - 0s - loss: 0.2333 - mean_squared_error: 0.0679 - acc: 0.9177 - val_loss: 0.2844 - val_mean_squared_error: 0.0887 - val_acc: 0.8606\n",
      "Epoch 398/3000\n",
      " - 0s - loss: 0.2337 - mean_squared_error: 0.0687 - acc: 0.9119 - val_loss: 0.2844 - val_mean_squared_error: 0.0886 - val_acc: 0.8606\n",
      "Epoch 399/3000\n",
      " - 0s - loss: 0.2330 - mean_squared_error: 0.0681 - acc: 0.9154 - val_loss: 0.2843 - val_mean_squared_error: 0.0886 - val_acc: 0.8606\n",
      "Epoch 400/3000\n",
      " - 0s - loss: 0.2366 - mean_squared_error: 0.0691 - acc: 0.9096 - val_loss: 0.2843 - val_mean_squared_error: 0.0886 - val_acc: 0.8606\n",
      "287/287 [==============================] - 0s 32us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['loss', 'mean_squared_error', 'acc'],\n",
       " [0.28427964459312915, 0.08864035472948792, 0.8606271781157118])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(x_train_norm, y_train, validation_data=(x_test_norm, y_test), epochs=3000, batch_size=512,\n",
    "          callbacks=[clr, stop], verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(x_test_norm, y_test)\n",
    "model.metrics_names, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_preds = model.predict_classes(x_test_norm)\n",
    "nn_pos = model.predict_proba(x_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8606271777003485,\n",
       " 0.29772530029229904,\n",
       " 0.9460563077584354,\n",
       " 0.28427964274522927)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(nn_preds), rmse(nn_pos), auroc(nn_pos), logloss(nn_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.8606271777003485,\n",
    " 0.29772530029229904,\n",
    " 0.9460563077584354,\n",
    " 0.28427964274522927)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['gbc_preds'] = gbc.predict_proba(x_train).T[1]\n",
    "test_df['gbc_preds'] = gbc.predict_proba(x_test).T[1]\n",
    "train_df['rfc_preds'] = rfc.predict_proba(x_train).T[1]\n",
    "test_df['rfc_preds'] = rfc.predict_proba(x_test).T[1]\n",
    "train_df['etc_preds'] = etc.predict_proba(x_train).T[1]\n",
    "test_df['etc_preds'] = etc.predict_proba(x_test).T[1]\n",
    "train_df['nn_preds'] = model.predict_proba(x_train_norm)\n",
    "test_df['nn_preds'] = model.predict_proba(x_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(f'{PATH}train_preds.csv')\n",
    "test_df.to_csv(f'{PATH}test_preds.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
