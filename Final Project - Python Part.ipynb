{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "PATH = '/Users/orendar/Downloads/dataverse_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>camp.length</th>\n",
       "      <th>deminc</th>\n",
       "      <th>base.poll</th>\n",
       "      <th>base.und</th>\n",
       "      <th>office</th>\n",
       "      <th>d.gone.neg</th>\n",
       "      <th>d.gone.neg.l1</th>\n",
       "      <th>d.gone.neg.l2</th>\n",
       "      <th>d.neg.frac.l3</th>\n",
       "      <th>...</th>\n",
       "      <th>y2002</th>\n",
       "      <th>y2000</th>\n",
       "      <th>pos.prob.subset</th>\n",
       "      <th>missing</th>\n",
       "      <th>bart.sw</th>\n",
       "      <th>gbm.sw</th>\n",
       "      <th>gam.sw</th>\n",
       "      <th>bart.pscore</th>\n",
       "      <th>gbm.pscore</th>\n",
       "      <th>gam.pscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2002</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  camp.length  deminc  base.poll  base.und  office  d.gone.neg  \\\n",
       "1  2002           23       1  45.744681       6.0       0           0   \n",
       "2  2002           23       1  45.744681       6.0       0           0   \n",
       "3  2002           23       1  45.744681       6.0       0           1   \n",
       "4  2002           23       1  45.744681       6.0       0           1   \n",
       "5  2002           23       1  45.744681       6.0       0           1   \n",
       "\n",
       "   d.gone.neg.l1  d.gone.neg.l2  d.neg.frac.l3     ...      y2002  y2000  \\\n",
       "1              0              0       0.000000     ...          1      0   \n",
       "2              0              0       0.000000     ...          1      0   \n",
       "3              1              0       0.000000     ...          1      0   \n",
       "4              1              1       0.000000     ...          1      0   \n",
       "5              1              1       0.071429     ...          1      0   \n",
       "\n",
       "   pos.prob.subset  missing  bart.sw  gbm.sw  gam.sw  bart.pscore  gbm.pscore  \\\n",
       "1             True    False      NaN     NaN     NaN          NaN         NaN   \n",
       "2             True    False      NaN     NaN     NaN          NaN         NaN   \n",
       "3             True    False      NaN     NaN     NaN          NaN         NaN   \n",
       "4             True    False      NaN     NaN     NaN          NaN         NaN   \n",
       "5             True    False      NaN     NaN     NaN          NaN         NaN   \n",
       "\n",
       "   gam.pscore  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(f'{PATH}train.csv', index_col = 0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>camp.length</th>\n",
       "      <th>deminc</th>\n",
       "      <th>base.poll</th>\n",
       "      <th>base.und</th>\n",
       "      <th>office</th>\n",
       "      <th>d.gone.neg</th>\n",
       "      <th>d.gone.neg.l1</th>\n",
       "      <th>d.gone.neg.l2</th>\n",
       "      <th>d.neg.frac.l3</th>\n",
       "      <th>...</th>\n",
       "      <th>missing</th>\n",
       "      <th>bart.sw</th>\n",
       "      <th>gbm.sw</th>\n",
       "      <th>gam.sw</th>\n",
       "      <th>bart.pscore</th>\n",
       "      <th>gbm.pscore</th>\n",
       "      <th>gam.pscore</th>\n",
       "      <th>gam.pred</th>\n",
       "      <th>gbm.pred</th>\n",
       "      <th>bart.pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>44.736842</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853041</td>\n",
       "      <td>0.925549</td>\n",
       "      <td>0.976336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>63.636364</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013914</td>\n",
       "      <td>0.093114</td>\n",
       "      <td>0.066920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>62.765957</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.921248</td>\n",
       "      <td>0.908793</td>\n",
       "      <td>0.895841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>62.637363</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.222096</td>\n",
       "      <td>0.134856</td>\n",
       "      <td>0.064143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>66.455237</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044348</td>\n",
       "      <td>0.219977</td>\n",
       "      <td>0.216478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  camp.length  deminc  base.poll  base.und  office  d.gone.neg  \\\n",
       "1  2002           13       0  44.736842      24.0       1           1   \n",
       "2  2006           23       1  63.636364      12.0       0           0   \n",
       "3  2002           23       0  62.765957       6.0       0           1   \n",
       "4  2006           27       1  62.637363       9.0       1           0   \n",
       "5  2006           15       1  66.455237       9.0       0           0   \n",
       "\n",
       "   d.gone.neg.l1  d.gone.neg.l2  d.neg.frac.l3    ...      missing  bart.sw  \\\n",
       "1              1              1       1.000000    ...        False      NaN   \n",
       "2              0              0       0.000000    ...        False      NaN   \n",
       "3              1              1       0.176471    ...        False      NaN   \n",
       "4              0              0       0.090909    ...        False      NaN   \n",
       "5              0              0       0.000000    ...        False      NaN   \n",
       "\n",
       "   gbm.sw  gam.sw  bart.pscore  gbm.pscore  gam.pscore  gam.pred  gbm.pred  \\\n",
       "1     NaN     NaN          NaN         NaN         NaN  0.853041  0.925549   \n",
       "2     NaN     NaN          NaN         NaN         NaN  0.013914  0.093114   \n",
       "3     NaN     NaN          NaN         NaN         NaN  0.921248  0.908793   \n",
       "4     NaN     NaN          NaN         NaN         NaN  0.222096  0.134856   \n",
       "5     NaN     NaN          NaN         NaN         NaN  0.044348  0.219977   \n",
       "\n",
       "   bart.pred  \n",
       "1   0.976336  \n",
       "2   0.066920  \n",
       "3   0.895841  \n",
       "4   0.064143  \n",
       "5   0.216478  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(f'{PATH}test.csv',  index_col = 0)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((818, 29), (818,), (274, 29), (274,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\"d.gone.neg.l1\", \"d.gone.neg.l2\", \"d.neg.frac.l3\", \"week\",\n",
    "            \"camp.length\", \"base.poll\", \"y2000\", \"y2002\", \"y2004\", \"y2006\",\n",
    "            \"base.und\", \"office\", \"dem.polls.l1\", \"dem.polls.l2\", \"neg.rep.l1\",\n",
    "            \"neg.rep.l2\", \"r.neg.frac.l2\", \"r.neg.frac.l3\", \"num.rep.l1\",\n",
    "            \"num.rep.l2\", \"num.dem.l1\", \"num.dem.l2\", \"undother.l1\",\n",
    "            \"undother.l2\", \"deminc\", \"dem.contrib.l1\", \"dem.contrib.l2\",\n",
    "            \"rep.contrib.l1\", \"rep.contrib.l2\"]\n",
    "\n",
    "target = \"d.gone.neg\"\n",
    "\n",
    "train_df = train_df[features+[target]].dropna()\n",
    "y_train = train_df[target]\n",
    "x_train = train_df.drop(target, axis=1)\n",
    "test_df = test_df[features+[target]].dropna()\n",
    "y_test = test_df[target]\n",
    "x_test = test_df.drop(target, axis=1)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import *\n",
    "from sklearn.metrics import *\n",
    "rs = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=100, max_features='sqrt', random_state=rs)\n",
    "rfc = RandomForestClassifier(n_estimators=500, random_state=rs, n_jobs=-1)\n",
    "etc = ExtraTreesClassifier(n_estimators=500, random_state=rs, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc.fit(x_train, y_train)\n",
    "rfc.fit(x_train, y_train)\n",
    "etc.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_preds = gbc.predict(x_test)\n",
    "rfc_preds = rfc.predict(x_test)\n",
    "etc_preds = etc.predict(x_test)\n",
    "gbc_prob_preds = gbc.predict_proba(x_test)\n",
    "rfc_prob_preds = rfc.predict_proba(x_test)\n",
    "etc_prob_preds = etc.predict_proba(x_test)\n",
    "gbc_pos = gbc_prob_preds.T[1]\n",
    "rfc_pos = rfc_prob_preds.T[1]\n",
    "etc_pos = etc_prob_preds.T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(preds): return mean_squared_error(y_test, preds)**.5\n",
    "def auroc(preds): return roc_auc_score(y_test, preds)\n",
    "def accuracy(preds): return accuracy_score(y_test, preds)\n",
    "def logloss(preds): return log_loss(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2911546724006993, 0.2997949664317435, 0.3041994879468953)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(gbc_pos), rmse(rfc_pos), rmse(etc_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8795620437956204, 0.8686131386861314, 0.8576642335766423)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(gbc_preds), accuracy(rfc_preds), accuracy(etc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9397605083088955, 0.933284457478006, 0.9353005865102639)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc(gbc_pos), auroc(rfc_pos), auroc(etc_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2821562723408976, 0.3029121745427702, 0.2943411109232128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss(gbc_pos), logloss(rfc_pos), logloss(etc_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>LogLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBM</th>\n",
       "      <td>0.879562</td>\n",
       "      <td>0.291155</td>\n",
       "      <td>0.939761</td>\n",
       "      <td>0.282156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.868613</td>\n",
       "      <td>0.299795</td>\n",
       "      <td>0.933284</td>\n",
       "      <td>0.302912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET</th>\n",
       "      <td>0.857664</td>\n",
       "      <td>0.304199</td>\n",
       "      <td>0.935301</td>\n",
       "      <td>0.294341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy      RMSE     AUROC   LogLoss\n",
       "GBM  0.879562  0.291155  0.939761  0.282156\n",
       "RF   0.868613  0.299795  0.933284  0.302912\n",
       "ET   0.857664  0.304199  0.935301  0.294341"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=[[accuracy(gbc_preds), rmse(gbc_pos), auroc(gbc_pos), logloss(gbc_pos)],\n",
    "                        [accuracy(rfc_preds), rmse(rfc_pos), auroc(rfc_pos), logloss(rfc_pos)],\n",
    "                        [accuracy(etc_preds), rmse(etc_pos), auroc(etc_pos), logloss(etc_pos)]],\n",
    "                  index=['GBM', 'RF', 'ET'],\n",
    "                  columns=['Accuracy', 'RMSE', 'AUROC', 'LogLoss'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrrrr}\\n\\\\toprule\\n{} &  Accuracy &      RMSE &     AUROC &   LogLoss \\\\\\\\\\n\\\\midrule\\nGBM &  0.879562 &  0.291155 &  0.939761 &  0.282156 \\\\\\\\\\nRF  &  0.868613 &  0.299795 &  0.933284 &  0.302912 \\\\\\\\\\nET  &  0.857664 &  0.304199 &  0.935301 &  0.294341 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orendar/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.utils import *\n",
    "from keras.optimizers import *\n",
    "from sklearn.preprocessing import *\n",
    "from clr import *\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mat, y_train_mat = x_train.as_matrix(), y_train.as_matrix().reshape(-1, 1)\n",
    "x_test_mat, y_test_mat = x_test.as_matrix(), y_test.as_matrix().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_norm = scaler.fit_transform(x_train_mat)\n",
    "x_test_norm = scaler.transform(x_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4096, input_dim=29, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "opt = optimizers.adam(amsgrad=True)\n",
    "#opt = optimizers.SGD(momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['mse', 'accuracy'])\n",
    "\n",
    "#callbacks arsenal\n",
    "def sched(idx, lr): return lr*0.9 if idx % 10 == 0 else lr\n",
    "lrsched = LearningRateScheduler(sched, verbose=0)\n",
    "reducelr = ReduceLROnPlateau(factor=0.8, patience=2)\n",
    "stop = EarlyStopping(patience=50)\n",
    "clr = CyclicLR(base_lr=1e-5, max_lr=1e-4, step_size=15, mode='triangular', scale_mode='cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 818 samples, validate on 274 samples\n",
      "Epoch 1/3000\n",
      " - 0s - loss: 0.7078 - mean_squared_error: 0.2573 - acc: 0.4120 - val_loss: 0.6985 - val_mean_squared_error: 0.2527 - val_acc: 0.4489\n",
      "Epoch 2/3000\n",
      " - 0s - loss: 0.7007 - mean_squared_error: 0.2538 - acc: 0.4450 - val_loss: 0.6902 - val_mean_squared_error: 0.2485 - val_acc: 0.5182\n",
      "Epoch 3/3000\n",
      " - 0s - loss: 0.6939 - mean_squared_error: 0.2504 - acc: 0.5147 - val_loss: 0.6783 - val_mean_squared_error: 0.2426 - val_acc: 0.5876\n",
      "Epoch 4/3000\n",
      " - 0s - loss: 0.6800 - mean_squared_error: 0.2435 - acc: 0.6149 - val_loss: 0.6632 - val_mean_squared_error: 0.2351 - val_acc: 0.7044\n",
      "Epoch 5/3000\n",
      " - 0s - loss: 0.6634 - mean_squared_error: 0.2353 - acc: 0.6797 - val_loss: 0.6456 - val_mean_squared_error: 0.2264 - val_acc: 0.7664\n",
      "Epoch 6/3000\n",
      " - 0s - loss: 0.6424 - mean_squared_error: 0.2250 - acc: 0.7213 - val_loss: 0.6258 - val_mean_squared_error: 0.2168 - val_acc: 0.7847\n",
      "Epoch 7/3000\n",
      " - 0s - loss: 0.6252 - mean_squared_error: 0.2166 - acc: 0.7579 - val_loss: 0.6047 - val_mean_squared_error: 0.2067 - val_acc: 0.7920\n",
      "Epoch 8/3000\n",
      " - 0s - loss: 0.6030 - mean_squared_error: 0.2059 - acc: 0.7934 - val_loss: 0.5830 - val_mean_squared_error: 0.1966 - val_acc: 0.7993\n",
      "Epoch 9/3000\n",
      " - 0s - loss: 0.5850 - mean_squared_error: 0.1976 - acc: 0.7848 - val_loss: 0.5648 - val_mean_squared_error: 0.1883 - val_acc: 0.7993\n",
      "Epoch 10/3000\n",
      " - 0s - loss: 0.5658 - mean_squared_error: 0.1888 - acc: 0.7971 - val_loss: 0.5505 - val_mean_squared_error: 0.1820 - val_acc: 0.8029\n",
      "Epoch 11/3000\n",
      " - 0s - loss: 0.5532 - mean_squared_error: 0.1831 - acc: 0.8020 - val_loss: 0.5395 - val_mean_squared_error: 0.1772 - val_acc: 0.8066\n",
      "Epoch 12/3000\n",
      " - 0s - loss: 0.5432 - mean_squared_error: 0.1789 - acc: 0.7946 - val_loss: 0.5310 - val_mean_squared_error: 0.1736 - val_acc: 0.8066\n",
      "Epoch 13/3000\n",
      " - 0s - loss: 0.5343 - mean_squared_error: 0.1749 - acc: 0.8044 - val_loss: 0.5249 - val_mean_squared_error: 0.1710 - val_acc: 0.8066\n",
      "Epoch 14/3000\n",
      " - 0s - loss: 0.5300 - mean_squared_error: 0.1729 - acc: 0.7995 - val_loss: 0.5207 - val_mean_squared_error: 0.1692 - val_acc: 0.8139\n",
      "Epoch 15/3000\n",
      " - 0s - loss: 0.5241 - mean_squared_error: 0.1703 - acc: 0.8093 - val_loss: 0.5183 - val_mean_squared_error: 0.1682 - val_acc: 0.8139\n",
      "Epoch 16/3000\n",
      " - 0s - loss: 0.5285 - mean_squared_error: 0.1724 - acc: 0.8068 - val_loss: 0.5166 - val_mean_squared_error: 0.1675 - val_acc: 0.8139\n",
      "Epoch 17/3000\n",
      " - 0s - loss: 0.5247 - mean_squared_error: 0.1707 - acc: 0.8117 - val_loss: 0.5136 - val_mean_squared_error: 0.1662 - val_acc: 0.8139\n",
      "Epoch 18/3000\n",
      " - 0s - loss: 0.5164 - mean_squared_error: 0.1672 - acc: 0.8044 - val_loss: 0.5092 - val_mean_squared_error: 0.1644 - val_acc: 0.8212\n",
      "Epoch 19/3000\n",
      " - 0s - loss: 0.5155 - mean_squared_error: 0.1668 - acc: 0.8068 - val_loss: 0.5037 - val_mean_squared_error: 0.1621 - val_acc: 0.8212\n",
      "Epoch 20/3000\n",
      " - 0s - loss: 0.5093 - mean_squared_error: 0.1642 - acc: 0.8105 - val_loss: 0.4971 - val_mean_squared_error: 0.1594 - val_acc: 0.8212\n",
      "Epoch 21/3000\n",
      " - 0s - loss: 0.5025 - mean_squared_error: 0.1616 - acc: 0.8166 - val_loss: 0.4897 - val_mean_squared_error: 0.1564 - val_acc: 0.8212\n",
      "Epoch 22/3000\n",
      " - 0s - loss: 0.4959 - mean_squared_error: 0.1587 - acc: 0.8154 - val_loss: 0.4817 - val_mean_squared_error: 0.1532 - val_acc: 0.8285\n",
      "Epoch 23/3000\n",
      " - 0s - loss: 0.4888 - mean_squared_error: 0.1558 - acc: 0.8142 - val_loss: 0.4732 - val_mean_squared_error: 0.1498 - val_acc: 0.8285\n",
      "Epoch 24/3000\n",
      " - 0s - loss: 0.4813 - mean_squared_error: 0.1530 - acc: 0.8178 - val_loss: 0.4658 - val_mean_squared_error: 0.1469 - val_acc: 0.8285\n",
      "Epoch 25/3000\n",
      " - 0s - loss: 0.4729 - mean_squared_error: 0.1497 - acc: 0.8203 - val_loss: 0.4598 - val_mean_squared_error: 0.1446 - val_acc: 0.8285\n",
      "Epoch 26/3000\n",
      " - 0s - loss: 0.4650 - mean_squared_error: 0.1463 - acc: 0.8215 - val_loss: 0.4550 - val_mean_squared_error: 0.1428 - val_acc: 0.8285\n",
      "Epoch 27/3000\n",
      " - 0s - loss: 0.4642 - mean_squared_error: 0.1461 - acc: 0.8142 - val_loss: 0.4514 - val_mean_squared_error: 0.1414 - val_acc: 0.8394\n",
      "Epoch 28/3000\n",
      " - 0s - loss: 0.4603 - mean_squared_error: 0.1448 - acc: 0.8240 - val_loss: 0.4486 - val_mean_squared_error: 0.1403 - val_acc: 0.8394\n",
      "Epoch 29/3000\n",
      " - 0s - loss: 0.4569 - mean_squared_error: 0.1433 - acc: 0.8337 - val_loss: 0.4467 - val_mean_squared_error: 0.1396 - val_acc: 0.8394\n",
      "Epoch 30/3000\n",
      " - 0s - loss: 0.4562 - mean_squared_error: 0.1434 - acc: 0.8264 - val_loss: 0.4455 - val_mean_squared_error: 0.1391 - val_acc: 0.8394\n",
      "Epoch 31/3000\n",
      " - 0s - loss: 0.4560 - mean_squared_error: 0.1430 - acc: 0.8252 - val_loss: 0.4448 - val_mean_squared_error: 0.1388 - val_acc: 0.8394\n",
      "Epoch 32/3000\n",
      " - 0s - loss: 0.4536 - mean_squared_error: 0.1419 - acc: 0.8313 - val_loss: 0.4433 - val_mean_squared_error: 0.1383 - val_acc: 0.8394\n",
      "Epoch 33/3000\n",
      " - 0s - loss: 0.4515 - mean_squared_error: 0.1413 - acc: 0.8301 - val_loss: 0.4413 - val_mean_squared_error: 0.1375 - val_acc: 0.8394\n",
      "Epoch 34/3000\n",
      " - 0s - loss: 0.4510 - mean_squared_error: 0.1413 - acc: 0.8289 - val_loss: 0.4386 - val_mean_squared_error: 0.1364 - val_acc: 0.8394\n",
      "Epoch 35/3000\n",
      " - 0s - loss: 0.4472 - mean_squared_error: 0.1395 - acc: 0.8252 - val_loss: 0.4354 - val_mean_squared_error: 0.1352 - val_acc: 0.8394\n",
      "Epoch 36/3000\n",
      " - 0s - loss: 0.4418 - mean_squared_error: 0.1378 - acc: 0.8374 - val_loss: 0.4316 - val_mean_squared_error: 0.1338 - val_acc: 0.8394\n",
      "Epoch 37/3000\n",
      " - 0s - loss: 0.4381 - mean_squared_error: 0.1358 - acc: 0.8362 - val_loss: 0.4274 - val_mean_squared_error: 0.1322 - val_acc: 0.8394\n",
      "Epoch 38/3000\n",
      " - 0s - loss: 0.4371 - mean_squared_error: 0.1359 - acc: 0.8325 - val_loss: 0.4227 - val_mean_squared_error: 0.1304 - val_acc: 0.8394\n",
      "Epoch 39/3000\n",
      " - 0s - loss: 0.4307 - mean_squared_error: 0.1333 - acc: 0.8386 - val_loss: 0.4186 - val_mean_squared_error: 0.1289 - val_acc: 0.8394\n",
      "Epoch 40/3000\n",
      " - 0s - loss: 0.4272 - mean_squared_error: 0.1321 - acc: 0.8374 - val_loss: 0.4151 - val_mean_squared_error: 0.1276 - val_acc: 0.8358\n",
      "Epoch 41/3000\n",
      " - 0s - loss: 0.4220 - mean_squared_error: 0.1300 - acc: 0.8447 - val_loss: 0.4123 - val_mean_squared_error: 0.1266 - val_acc: 0.8358\n",
      "Epoch 42/3000\n",
      " - 0s - loss: 0.4200 - mean_squared_error: 0.1295 - acc: 0.8374 - val_loss: 0.4101 - val_mean_squared_error: 0.1257 - val_acc: 0.8358\n",
      "Epoch 43/3000\n",
      " - 0s - loss: 0.4185 - mean_squared_error: 0.1289 - acc: 0.8399 - val_loss: 0.4084 - val_mean_squared_error: 0.1251 - val_acc: 0.8358\n",
      "Epoch 44/3000\n",
      " - 0s - loss: 0.4182 - mean_squared_error: 0.1287 - acc: 0.8386 - val_loss: 0.4072 - val_mean_squared_error: 0.1247 - val_acc: 0.8358\n",
      "Epoch 45/3000\n",
      " - 0s - loss: 0.4181 - mean_squared_error: 0.1289 - acc: 0.8411 - val_loss: 0.4065 - val_mean_squared_error: 0.1244 - val_acc: 0.8358\n",
      "Epoch 46/3000\n",
      " - 0s - loss: 0.4169 - mean_squared_error: 0.1283 - acc: 0.8423 - val_loss: 0.4060 - val_mean_squared_error: 0.1243 - val_acc: 0.8358\n",
      "Epoch 47/3000\n",
      " - 0s - loss: 0.4151 - mean_squared_error: 0.1279 - acc: 0.8411 - val_loss: 0.4051 - val_mean_squared_error: 0.1239 - val_acc: 0.8358\n",
      "Epoch 48/3000\n",
      " - 0s - loss: 0.4131 - mean_squared_error: 0.1271 - acc: 0.8374 - val_loss: 0.4038 - val_mean_squared_error: 0.1235 - val_acc: 0.8358\n",
      "Epoch 49/3000\n",
      " - 0s - loss: 0.4097 - mean_squared_error: 0.1255 - acc: 0.8460 - val_loss: 0.4021 - val_mean_squared_error: 0.1228 - val_acc: 0.8358\n",
      "Epoch 50/3000\n",
      " - 0s - loss: 0.4113 - mean_squared_error: 0.1261 - acc: 0.8350 - val_loss: 0.4000 - val_mean_squared_error: 0.1221 - val_acc: 0.8358\n",
      "Epoch 51/3000\n",
      " - 0s - loss: 0.4078 - mean_squared_error: 0.1250 - acc: 0.8423 - val_loss: 0.3976 - val_mean_squared_error: 0.1212 - val_acc: 0.8358\n",
      "Epoch 52/3000\n",
      " - 0s - loss: 0.4049 - mean_squared_error: 0.1242 - acc: 0.8435 - val_loss: 0.3948 - val_mean_squared_error: 0.1202 - val_acc: 0.8431\n",
      "Epoch 53/3000\n",
      " - 0s - loss: 0.4015 - mean_squared_error: 0.1225 - acc: 0.8484 - val_loss: 0.3918 - val_mean_squared_error: 0.1191 - val_acc: 0.8467\n",
      "Epoch 54/3000\n",
      " - 0s - loss: 0.4001 - mean_squared_error: 0.1222 - acc: 0.8509 - val_loss: 0.3890 - val_mean_squared_error: 0.1181 - val_acc: 0.8467\n",
      "Epoch 55/3000\n",
      " - 0s - loss: 0.3994 - mean_squared_error: 0.1221 - acc: 0.8460 - val_loss: 0.3868 - val_mean_squared_error: 0.1173 - val_acc: 0.8467\n",
      "Epoch 56/3000\n",
      " - 0s - loss: 0.3949 - mean_squared_error: 0.1206 - acc: 0.8509 - val_loss: 0.3849 - val_mean_squared_error: 0.1167 - val_acc: 0.8467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/3000\n",
      " - 0s - loss: 0.3914 - mean_squared_error: 0.1189 - acc: 0.8533 - val_loss: 0.3834 - val_mean_squared_error: 0.1161 - val_acc: 0.8467\n",
      "Epoch 58/3000\n",
      " - 0s - loss: 0.3925 - mean_squared_error: 0.1193 - acc: 0.8521 - val_loss: 0.3822 - val_mean_squared_error: 0.1157 - val_acc: 0.8467\n",
      "Epoch 59/3000\n",
      " - 0s - loss: 0.3876 - mean_squared_error: 0.1179 - acc: 0.8521 - val_loss: 0.3814 - val_mean_squared_error: 0.1154 - val_acc: 0.8467\n",
      "Epoch 60/3000\n",
      " - 0s - loss: 0.3893 - mean_squared_error: 0.1184 - acc: 0.8533 - val_loss: 0.3809 - val_mean_squared_error: 0.1153 - val_acc: 0.8467\n",
      "Epoch 61/3000\n",
      " - 0s - loss: 0.3884 - mean_squared_error: 0.1179 - acc: 0.8557 - val_loss: 0.3806 - val_mean_squared_error: 0.1152 - val_acc: 0.8467\n",
      "Epoch 62/3000\n",
      " - 0s - loss: 0.3884 - mean_squared_error: 0.1182 - acc: 0.8484 - val_loss: 0.3800 - val_mean_squared_error: 0.1149 - val_acc: 0.8467\n",
      "Epoch 63/3000\n",
      " - 0s - loss: 0.3881 - mean_squared_error: 0.1179 - acc: 0.8484 - val_loss: 0.3790 - val_mean_squared_error: 0.1146 - val_acc: 0.8467\n",
      "Epoch 64/3000\n",
      " - 0s - loss: 0.3871 - mean_squared_error: 0.1174 - acc: 0.8472 - val_loss: 0.3778 - val_mean_squared_error: 0.1142 - val_acc: 0.8467\n",
      "Epoch 65/3000\n",
      " - 0s - loss: 0.3843 - mean_squared_error: 0.1167 - acc: 0.8557 - val_loss: 0.3764 - val_mean_squared_error: 0.1137 - val_acc: 0.8504\n",
      "Epoch 66/3000\n",
      " - 0s - loss: 0.3843 - mean_squared_error: 0.1166 - acc: 0.8557 - val_loss: 0.3746 - val_mean_squared_error: 0.1131 - val_acc: 0.8504\n",
      "Epoch 67/3000\n",
      " - 0s - loss: 0.3812 - mean_squared_error: 0.1153 - acc: 0.8606 - val_loss: 0.3726 - val_mean_squared_error: 0.1124 - val_acc: 0.8540\n",
      "Epoch 68/3000\n",
      " - 0s - loss: 0.3795 - mean_squared_error: 0.1146 - acc: 0.8582 - val_loss: 0.3704 - val_mean_squared_error: 0.1116 - val_acc: 0.8540\n",
      "Epoch 69/3000\n",
      " - 0s - loss: 0.3746 - mean_squared_error: 0.1132 - acc: 0.8606 - val_loss: 0.3684 - val_mean_squared_error: 0.1110 - val_acc: 0.8540\n",
      "Epoch 70/3000\n",
      " - 0s - loss: 0.3751 - mean_squared_error: 0.1130 - acc: 0.8582 - val_loss: 0.3667 - val_mean_squared_error: 0.1104 - val_acc: 0.8540\n",
      "Epoch 71/3000\n",
      " - 0s - loss: 0.3694 - mean_squared_error: 0.1117 - acc: 0.8631 - val_loss: 0.3653 - val_mean_squared_error: 0.1099 - val_acc: 0.8540\n",
      "Epoch 72/3000\n",
      " - 0s - loss: 0.3706 - mean_squared_error: 0.1118 - acc: 0.8594 - val_loss: 0.3642 - val_mean_squared_error: 0.1096 - val_acc: 0.8577\n",
      "Epoch 73/3000\n",
      " - 0s - loss: 0.3680 - mean_squared_error: 0.1109 - acc: 0.8557 - val_loss: 0.3634 - val_mean_squared_error: 0.1093 - val_acc: 0.8577\n",
      "Epoch 74/3000\n",
      " - 0s - loss: 0.3698 - mean_squared_error: 0.1114 - acc: 0.8594 - val_loss: 0.3628 - val_mean_squared_error: 0.1091 - val_acc: 0.8577\n",
      "Epoch 75/3000\n",
      " - 0s - loss: 0.3671 - mean_squared_error: 0.1103 - acc: 0.8655 - val_loss: 0.3624 - val_mean_squared_error: 0.1089 - val_acc: 0.8577\n",
      "Epoch 76/3000\n",
      " - 0s - loss: 0.3667 - mean_squared_error: 0.1108 - acc: 0.8631 - val_loss: 0.3621 - val_mean_squared_error: 0.1089 - val_acc: 0.8577\n",
      "Epoch 77/3000\n",
      " - 0s - loss: 0.3670 - mean_squared_error: 0.1107 - acc: 0.8606 - val_loss: 0.3616 - val_mean_squared_error: 0.1087 - val_acc: 0.8577\n",
      "Epoch 78/3000\n",
      " - 0s - loss: 0.3684 - mean_squared_error: 0.1111 - acc: 0.8655 - val_loss: 0.3609 - val_mean_squared_error: 0.1085 - val_acc: 0.8577\n",
      "Epoch 79/3000\n",
      " - 0s - loss: 0.3687 - mean_squared_error: 0.1109 - acc: 0.8582 - val_loss: 0.3600 - val_mean_squared_error: 0.1081 - val_acc: 0.8577\n",
      "Epoch 80/3000\n",
      " - 0s - loss: 0.3675 - mean_squared_error: 0.1104 - acc: 0.8545 - val_loss: 0.3588 - val_mean_squared_error: 0.1078 - val_acc: 0.8577\n",
      "Epoch 81/3000\n",
      " - 0s - loss: 0.3640 - mean_squared_error: 0.1093 - acc: 0.8667 - val_loss: 0.3574 - val_mean_squared_error: 0.1073 - val_acc: 0.8577\n",
      "Epoch 82/3000\n",
      " - 0s - loss: 0.3611 - mean_squared_error: 0.1087 - acc: 0.8680 - val_loss: 0.3558 - val_mean_squared_error: 0.1068 - val_acc: 0.8577\n",
      "Epoch 83/3000\n",
      " - 0s - loss: 0.3596 - mean_squared_error: 0.1079 - acc: 0.8680 - val_loss: 0.3541 - val_mean_squared_error: 0.1062 - val_acc: 0.8577\n",
      "Epoch 84/3000\n",
      " - 0s - loss: 0.3602 - mean_squared_error: 0.1087 - acc: 0.8643 - val_loss: 0.3525 - val_mean_squared_error: 0.1057 - val_acc: 0.8577\n",
      "Epoch 85/3000\n",
      " - 0s - loss: 0.3548 - mean_squared_error: 0.1063 - acc: 0.8729 - val_loss: 0.3512 - val_mean_squared_error: 0.1053 - val_acc: 0.8577\n",
      "Epoch 86/3000\n",
      " - 0s - loss: 0.3550 - mean_squared_error: 0.1065 - acc: 0.8667 - val_loss: 0.3500 - val_mean_squared_error: 0.1049 - val_acc: 0.8577\n",
      "Epoch 87/3000\n",
      " - 0s - loss: 0.3525 - mean_squared_error: 0.1056 - acc: 0.8655 - val_loss: 0.3492 - val_mean_squared_error: 0.1047 - val_acc: 0.8577\n",
      "Epoch 88/3000\n",
      " - 0s - loss: 0.3529 - mean_squared_error: 0.1057 - acc: 0.8765 - val_loss: 0.3485 - val_mean_squared_error: 0.1045 - val_acc: 0.8577\n",
      "Epoch 89/3000\n",
      " - 0s - loss: 0.3497 - mean_squared_error: 0.1042 - acc: 0.8716 - val_loss: 0.3480 - val_mean_squared_error: 0.1043 - val_acc: 0.8577\n",
      "Epoch 90/3000\n",
      " - 0s - loss: 0.3500 - mean_squared_error: 0.1047 - acc: 0.8765 - val_loss: 0.3477 - val_mean_squared_error: 0.1042 - val_acc: 0.8577\n",
      "Epoch 91/3000\n",
      " - 0s - loss: 0.3486 - mean_squared_error: 0.1043 - acc: 0.8729 - val_loss: 0.3475 - val_mean_squared_error: 0.1042 - val_acc: 0.8577\n",
      "Epoch 92/3000\n",
      " - 0s - loss: 0.3511 - mean_squared_error: 0.1051 - acc: 0.8704 - val_loss: 0.3471 - val_mean_squared_error: 0.1040 - val_acc: 0.8577\n",
      "Epoch 93/3000\n",
      " - 0s - loss: 0.3489 - mean_squared_error: 0.1042 - acc: 0.8680 - val_loss: 0.3465 - val_mean_squared_error: 0.1039 - val_acc: 0.8577\n",
      "Epoch 94/3000\n",
      " - 0s - loss: 0.3474 - mean_squared_error: 0.1038 - acc: 0.8765 - val_loss: 0.3458 - val_mean_squared_error: 0.1036 - val_acc: 0.8577\n",
      "Epoch 95/3000\n",
      " - 0s - loss: 0.3497 - mean_squared_error: 0.1046 - acc: 0.8716 - val_loss: 0.3449 - val_mean_squared_error: 0.1033 - val_acc: 0.8577\n",
      "Epoch 96/3000\n",
      " - 0s - loss: 0.3471 - mean_squared_error: 0.1033 - acc: 0.8692 - val_loss: 0.3438 - val_mean_squared_error: 0.1030 - val_acc: 0.8577\n",
      "Epoch 97/3000\n",
      " - 0s - loss: 0.3467 - mean_squared_error: 0.1038 - acc: 0.8692 - val_loss: 0.3425 - val_mean_squared_error: 0.1026 - val_acc: 0.8577\n",
      "Epoch 98/3000\n",
      " - 0s - loss: 0.3438 - mean_squared_error: 0.1030 - acc: 0.8716 - val_loss: 0.3411 - val_mean_squared_error: 0.1022 - val_acc: 0.8577\n",
      "Epoch 99/3000\n",
      " - 0s - loss: 0.3401 - mean_squared_error: 0.1018 - acc: 0.8753 - val_loss: 0.3399 - val_mean_squared_error: 0.1018 - val_acc: 0.8577\n",
      "Epoch 100/3000\n",
      " - 0s - loss: 0.3412 - mean_squared_error: 0.1022 - acc: 0.8704 - val_loss: 0.3388 - val_mean_squared_error: 0.1015 - val_acc: 0.8577\n",
      "Epoch 101/3000\n",
      " - 0s - loss: 0.3375 - mean_squared_error: 0.1005 - acc: 0.8778 - val_loss: 0.3379 - val_mean_squared_error: 0.1012 - val_acc: 0.8577\n",
      "Epoch 102/3000\n",
      " - 0s - loss: 0.3376 - mean_squared_error: 0.1007 - acc: 0.8741 - val_loss: 0.3372 - val_mean_squared_error: 0.1010 - val_acc: 0.8577\n",
      "Epoch 103/3000\n",
      " - 0s - loss: 0.3364 - mean_squared_error: 0.1003 - acc: 0.8753 - val_loss: 0.3366 - val_mean_squared_error: 0.1009 - val_acc: 0.8577\n",
      "Epoch 104/3000\n",
      " - 0s - loss: 0.3363 - mean_squared_error: 0.1004 - acc: 0.8729 - val_loss: 0.3362 - val_mean_squared_error: 0.1008 - val_acc: 0.8577\n",
      "Epoch 105/3000\n",
      " - 0s - loss: 0.3347 - mean_squared_error: 0.0995 - acc: 0.8753 - val_loss: 0.3360 - val_mean_squared_error: 0.1007 - val_acc: 0.8577\n",
      "Epoch 106/3000\n",
      " - 0s - loss: 0.3350 - mean_squared_error: 0.1000 - acc: 0.8729 - val_loss: 0.3358 - val_mean_squared_error: 0.1006 - val_acc: 0.8577\n",
      "Epoch 107/3000\n",
      " - 0s - loss: 0.3306 - mean_squared_error: 0.0982 - acc: 0.8778 - val_loss: 0.3355 - val_mean_squared_error: 0.1005 - val_acc: 0.8577\n",
      "Epoch 108/3000\n",
      " - 0s - loss: 0.3333 - mean_squared_error: 0.0992 - acc: 0.8729 - val_loss: 0.3351 - val_mean_squared_error: 0.1004 - val_acc: 0.8577\n",
      "Epoch 109/3000\n",
      " - 0s - loss: 0.3345 - mean_squared_error: 0.0996 - acc: 0.8753 - val_loss: 0.3345 - val_mean_squared_error: 0.1003 - val_acc: 0.8577\n",
      "Epoch 110/3000\n",
      " - 0s - loss: 0.3343 - mean_squared_error: 0.0994 - acc: 0.8826 - val_loss: 0.3338 - val_mean_squared_error: 0.1000 - val_acc: 0.8577\n",
      "Epoch 111/3000\n",
      " - 0s - loss: 0.3312 - mean_squared_error: 0.0987 - acc: 0.8753 - val_loss: 0.3329 - val_mean_squared_error: 0.0998 - val_acc: 0.8577\n",
      "Epoch 112/3000\n",
      " - 0s - loss: 0.3299 - mean_squared_error: 0.0982 - acc: 0.8802 - val_loss: 0.3319 - val_mean_squared_error: 0.0995 - val_acc: 0.8577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/3000\n",
      " - 0s - loss: 0.3306 - mean_squared_error: 0.0985 - acc: 0.8765 - val_loss: 0.3308 - val_mean_squared_error: 0.0992 - val_acc: 0.8577\n",
      "Epoch 114/3000\n",
      " - 0s - loss: 0.3277 - mean_squared_error: 0.0971 - acc: 0.8790 - val_loss: 0.3298 - val_mean_squared_error: 0.0989 - val_acc: 0.8577\n",
      "Epoch 115/3000\n",
      " - 0s - loss: 0.3263 - mean_squared_error: 0.0974 - acc: 0.8753 - val_loss: 0.3290 - val_mean_squared_error: 0.0987 - val_acc: 0.8577\n",
      "Epoch 116/3000\n",
      " - 0s - loss: 0.3296 - mean_squared_error: 0.0983 - acc: 0.8741 - val_loss: 0.3283 - val_mean_squared_error: 0.0985 - val_acc: 0.8577\n",
      "Epoch 117/3000\n",
      " - 0s - loss: 0.3267 - mean_squared_error: 0.0975 - acc: 0.8802 - val_loss: 0.3277 - val_mean_squared_error: 0.0984 - val_acc: 0.8577\n",
      "Epoch 118/3000\n",
      " - 0s - loss: 0.3238 - mean_squared_error: 0.0963 - acc: 0.8778 - val_loss: 0.3273 - val_mean_squared_error: 0.0983 - val_acc: 0.8577\n",
      "Epoch 119/3000\n",
      " - 0s - loss: 0.3245 - mean_squared_error: 0.0966 - acc: 0.8729 - val_loss: 0.3270 - val_mean_squared_error: 0.0982 - val_acc: 0.8577\n",
      "Epoch 120/3000\n",
      " - 0s - loss: 0.3220 - mean_squared_error: 0.0956 - acc: 0.8814 - val_loss: 0.3268 - val_mean_squared_error: 0.0981 - val_acc: 0.8577\n",
      "Epoch 121/3000\n",
      " - 0s - loss: 0.3225 - mean_squared_error: 0.0959 - acc: 0.8790 - val_loss: 0.3267 - val_mean_squared_error: 0.0981 - val_acc: 0.8577\n",
      "Epoch 122/3000\n",
      " - 0s - loss: 0.3239 - mean_squared_error: 0.0961 - acc: 0.8826 - val_loss: 0.3264 - val_mean_squared_error: 0.0980 - val_acc: 0.8577\n",
      "Epoch 123/3000\n",
      " - 0s - loss: 0.3216 - mean_squared_error: 0.0954 - acc: 0.8765 - val_loss: 0.3261 - val_mean_squared_error: 0.0979 - val_acc: 0.8577\n",
      "Epoch 124/3000\n",
      " - 0s - loss: 0.3231 - mean_squared_error: 0.0961 - acc: 0.8790 - val_loss: 0.3256 - val_mean_squared_error: 0.0978 - val_acc: 0.8613\n",
      "Epoch 125/3000\n",
      " - 0s - loss: 0.3203 - mean_squared_error: 0.0951 - acc: 0.8839 - val_loss: 0.3250 - val_mean_squared_error: 0.0977 - val_acc: 0.8613\n",
      "Epoch 126/3000\n",
      " - 0s - loss: 0.3199 - mean_squared_error: 0.0952 - acc: 0.8802 - val_loss: 0.3244 - val_mean_squared_error: 0.0975 - val_acc: 0.8613\n",
      "Epoch 127/3000\n",
      " - 0s - loss: 0.3188 - mean_squared_error: 0.0946 - acc: 0.8826 - val_loss: 0.3236 - val_mean_squared_error: 0.0973 - val_acc: 0.8613\n",
      "Epoch 128/3000\n",
      " - 0s - loss: 0.3180 - mean_squared_error: 0.0945 - acc: 0.8790 - val_loss: 0.3227 - val_mean_squared_error: 0.0971 - val_acc: 0.8613\n",
      "Epoch 129/3000\n",
      " - 0s - loss: 0.3158 - mean_squared_error: 0.0935 - acc: 0.8790 - val_loss: 0.3220 - val_mean_squared_error: 0.0969 - val_acc: 0.8650\n",
      "Epoch 130/3000\n",
      " - 0s - loss: 0.3157 - mean_squared_error: 0.0940 - acc: 0.8851 - val_loss: 0.3213 - val_mean_squared_error: 0.0967 - val_acc: 0.8650\n",
      "Epoch 131/3000\n",
      " - 0s - loss: 0.3166 - mean_squared_error: 0.0941 - acc: 0.8814 - val_loss: 0.3208 - val_mean_squared_error: 0.0966 - val_acc: 0.8650\n",
      "Epoch 132/3000\n",
      " - 0s - loss: 0.3135 - mean_squared_error: 0.0929 - acc: 0.8802 - val_loss: 0.3203 - val_mean_squared_error: 0.0965 - val_acc: 0.8650\n",
      "Epoch 133/3000\n",
      " - 0s - loss: 0.3141 - mean_squared_error: 0.0931 - acc: 0.8802 - val_loss: 0.3200 - val_mean_squared_error: 0.0964 - val_acc: 0.8650\n",
      "Epoch 134/3000\n",
      " - 0s - loss: 0.3152 - mean_squared_error: 0.0938 - acc: 0.8814 - val_loss: 0.3197 - val_mean_squared_error: 0.0963 - val_acc: 0.8650\n",
      "Epoch 135/3000\n",
      " - 0s - loss: 0.3161 - mean_squared_error: 0.0941 - acc: 0.8826 - val_loss: 0.3196 - val_mean_squared_error: 0.0963 - val_acc: 0.8650\n",
      "Epoch 136/3000\n",
      " - 0s - loss: 0.3143 - mean_squared_error: 0.0935 - acc: 0.8790 - val_loss: 0.3195 - val_mean_squared_error: 0.0963 - val_acc: 0.8650\n",
      "Epoch 137/3000\n",
      " - 0s - loss: 0.3150 - mean_squared_error: 0.0934 - acc: 0.8790 - val_loss: 0.3193 - val_mean_squared_error: 0.0962 - val_acc: 0.8650\n",
      "Epoch 138/3000\n",
      " - 0s - loss: 0.3114 - mean_squared_error: 0.0923 - acc: 0.8875 - val_loss: 0.3190 - val_mean_squared_error: 0.0962 - val_acc: 0.8650\n",
      "Epoch 139/3000\n",
      " - 0s - loss: 0.3130 - mean_squared_error: 0.0927 - acc: 0.8790 - val_loss: 0.3186 - val_mean_squared_error: 0.0961 - val_acc: 0.8650\n",
      "Epoch 140/3000\n",
      " - 0s - loss: 0.3115 - mean_squared_error: 0.0923 - acc: 0.8814 - val_loss: 0.3182 - val_mean_squared_error: 0.0960 - val_acc: 0.8650\n",
      "Epoch 141/3000\n",
      " - 0s - loss: 0.3118 - mean_squared_error: 0.0927 - acc: 0.8778 - val_loss: 0.3176 - val_mean_squared_error: 0.0958 - val_acc: 0.8650\n",
      "Epoch 142/3000\n",
      " - 0s - loss: 0.3112 - mean_squared_error: 0.0926 - acc: 0.8826 - val_loss: 0.3170 - val_mean_squared_error: 0.0957 - val_acc: 0.8650\n",
      "Epoch 143/3000\n",
      " - 0s - loss: 0.3086 - mean_squared_error: 0.0914 - acc: 0.8839 - val_loss: 0.3163 - val_mean_squared_error: 0.0955 - val_acc: 0.8650\n",
      "Epoch 144/3000\n",
      " - 0s - loss: 0.3095 - mean_squared_error: 0.0918 - acc: 0.8826 - val_loss: 0.3156 - val_mean_squared_error: 0.0954 - val_acc: 0.8650\n",
      "Epoch 145/3000\n",
      " - 0s - loss: 0.3083 - mean_squared_error: 0.0910 - acc: 0.8802 - val_loss: 0.3150 - val_mean_squared_error: 0.0952 - val_acc: 0.8650\n",
      "Epoch 146/3000\n",
      " - 0s - loss: 0.3064 - mean_squared_error: 0.0909 - acc: 0.8802 - val_loss: 0.3146 - val_mean_squared_error: 0.0951 - val_acc: 0.8650\n",
      "Epoch 147/3000\n",
      " - 0s - loss: 0.3070 - mean_squared_error: 0.0910 - acc: 0.8826 - val_loss: 0.3142 - val_mean_squared_error: 0.0950 - val_acc: 0.8650\n",
      "Epoch 148/3000\n",
      " - 0s - loss: 0.3049 - mean_squared_error: 0.0902 - acc: 0.8826 - val_loss: 0.3139 - val_mean_squared_error: 0.0950 - val_acc: 0.8650\n",
      "Epoch 149/3000\n",
      " - 0s - loss: 0.3042 - mean_squared_error: 0.0903 - acc: 0.8826 - val_loss: 0.3137 - val_mean_squared_error: 0.0949 - val_acc: 0.8650\n",
      "Epoch 150/3000\n",
      " - 0s - loss: 0.3055 - mean_squared_error: 0.0906 - acc: 0.8851 - val_loss: 0.3136 - val_mean_squared_error: 0.0949 - val_acc: 0.8650\n",
      "Epoch 151/3000\n",
      " - 0s - loss: 0.3055 - mean_squared_error: 0.0904 - acc: 0.8839 - val_loss: 0.3135 - val_mean_squared_error: 0.0949 - val_acc: 0.8650\n",
      "Epoch 152/3000\n",
      " - 0s - loss: 0.3009 - mean_squared_error: 0.0886 - acc: 0.8851 - val_loss: 0.3133 - val_mean_squared_error: 0.0948 - val_acc: 0.8650\n",
      "Epoch 153/3000\n",
      " - 0s - loss: 0.3039 - mean_squared_error: 0.0902 - acc: 0.8839 - val_loss: 0.3131 - val_mean_squared_error: 0.0948 - val_acc: 0.8650\n",
      "Epoch 154/3000\n",
      " - 0s - loss: 0.3032 - mean_squared_error: 0.0896 - acc: 0.8802 - val_loss: 0.3128 - val_mean_squared_error: 0.0947 - val_acc: 0.8650\n",
      "Epoch 155/3000\n",
      " - 0s - loss: 0.3013 - mean_squared_error: 0.0888 - acc: 0.8863 - val_loss: 0.3124 - val_mean_squared_error: 0.0946 - val_acc: 0.8686\n",
      "Epoch 156/3000\n",
      " - 0s - loss: 0.2992 - mean_squared_error: 0.0882 - acc: 0.8839 - val_loss: 0.3119 - val_mean_squared_error: 0.0945 - val_acc: 0.8686\n",
      "Epoch 157/3000\n",
      " - 0s - loss: 0.3017 - mean_squared_error: 0.0894 - acc: 0.8790 - val_loss: 0.3114 - val_mean_squared_error: 0.0944 - val_acc: 0.8686\n",
      "Epoch 158/3000\n",
      " - 0s - loss: 0.2992 - mean_squared_error: 0.0886 - acc: 0.8875 - val_loss: 0.3108 - val_mean_squared_error: 0.0943 - val_acc: 0.8723\n",
      "Epoch 159/3000\n",
      " - 0s - loss: 0.3019 - mean_squared_error: 0.0895 - acc: 0.8826 - val_loss: 0.3103 - val_mean_squared_error: 0.0941 - val_acc: 0.8723\n",
      "Epoch 160/3000\n",
      " - 0s - loss: 0.2950 - mean_squared_error: 0.0867 - acc: 0.8863 - val_loss: 0.3099 - val_mean_squared_error: 0.0941 - val_acc: 0.8723\n",
      "Epoch 161/3000\n",
      " - 0s - loss: 0.2974 - mean_squared_error: 0.0877 - acc: 0.8863 - val_loss: 0.3095 - val_mean_squared_error: 0.0940 - val_acc: 0.8723\n",
      "Epoch 162/3000\n",
      " - 0s - loss: 0.2971 - mean_squared_error: 0.0878 - acc: 0.8863 - val_loss: 0.3093 - val_mean_squared_error: 0.0939 - val_acc: 0.8723\n",
      "Epoch 163/3000\n",
      " - 0s - loss: 0.2953 - mean_squared_error: 0.0871 - acc: 0.8875 - val_loss: 0.3090 - val_mean_squared_error: 0.0939 - val_acc: 0.8723\n",
      "Epoch 164/3000\n",
      " - 0s - loss: 0.2968 - mean_squared_error: 0.0878 - acc: 0.8802 - val_loss: 0.3089 - val_mean_squared_error: 0.0939 - val_acc: 0.8723\n",
      "Epoch 165/3000\n",
      " - 0s - loss: 0.2960 - mean_squared_error: 0.0873 - acc: 0.8839 - val_loss: 0.3088 - val_mean_squared_error: 0.0938 - val_acc: 0.8723\n",
      "Epoch 166/3000\n",
      " - 0s - loss: 0.2950 - mean_squared_error: 0.0873 - acc: 0.8826 - val_loss: 0.3087 - val_mean_squared_error: 0.0938 - val_acc: 0.8723\n",
      "Epoch 167/3000\n",
      " - 0s - loss: 0.2980 - mean_squared_error: 0.0884 - acc: 0.8851 - val_loss: 0.3086 - val_mean_squared_error: 0.0938 - val_acc: 0.8686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/3000\n",
      " - 0s - loss: 0.2965 - mean_squared_error: 0.0877 - acc: 0.8839 - val_loss: 0.3084 - val_mean_squared_error: 0.0938 - val_acc: 0.8686\n",
      "Epoch 169/3000\n",
      " - 0s - loss: 0.2964 - mean_squared_error: 0.0876 - acc: 0.8851 - val_loss: 0.3082 - val_mean_squared_error: 0.0937 - val_acc: 0.8686\n",
      "Epoch 170/3000\n",
      " - 0s - loss: 0.2957 - mean_squared_error: 0.0874 - acc: 0.8826 - val_loss: 0.3079 - val_mean_squared_error: 0.0937 - val_acc: 0.8723\n",
      "Epoch 171/3000\n",
      " - 0s - loss: 0.2924 - mean_squared_error: 0.0863 - acc: 0.8839 - val_loss: 0.3075 - val_mean_squared_error: 0.0936 - val_acc: 0.8723\n",
      "Epoch 172/3000\n",
      " - 0s - loss: 0.2955 - mean_squared_error: 0.0873 - acc: 0.8826 - val_loss: 0.3071 - val_mean_squared_error: 0.0935 - val_acc: 0.8723\n",
      "Epoch 173/3000\n",
      " - 0s - loss: 0.2907 - mean_squared_error: 0.0858 - acc: 0.8888 - val_loss: 0.3067 - val_mean_squared_error: 0.0934 - val_acc: 0.8723\n",
      "Epoch 174/3000\n",
      " - 0s - loss: 0.2899 - mean_squared_error: 0.0855 - acc: 0.8912 - val_loss: 0.3063 - val_mean_squared_error: 0.0934 - val_acc: 0.8723\n",
      "Epoch 175/3000\n",
      " - 0s - loss: 0.2894 - mean_squared_error: 0.0856 - acc: 0.8875 - val_loss: 0.3060 - val_mean_squared_error: 0.0933 - val_acc: 0.8723\n",
      "Epoch 176/3000\n",
      " - 0s - loss: 0.2906 - mean_squared_error: 0.0859 - acc: 0.8888 - val_loss: 0.3057 - val_mean_squared_error: 0.0933 - val_acc: 0.8723\n",
      "Epoch 177/3000\n",
      " - 0s - loss: 0.2904 - mean_squared_error: 0.0857 - acc: 0.8900 - val_loss: 0.3055 - val_mean_squared_error: 0.0933 - val_acc: 0.8723\n",
      "Epoch 178/3000\n",
      " - 0s - loss: 0.2894 - mean_squared_error: 0.0852 - acc: 0.8875 - val_loss: 0.3053 - val_mean_squared_error: 0.0932 - val_acc: 0.8723\n",
      "Epoch 179/3000\n",
      " - 0s - loss: 0.2868 - mean_squared_error: 0.0845 - acc: 0.8900 - val_loss: 0.3052 - val_mean_squared_error: 0.0932 - val_acc: 0.8723\n",
      "Epoch 180/3000\n",
      " - 0s - loss: 0.2883 - mean_squared_error: 0.0852 - acc: 0.8863 - val_loss: 0.3052 - val_mean_squared_error: 0.0932 - val_acc: 0.8723\n",
      "Epoch 181/3000\n",
      " - 0s - loss: 0.2889 - mean_squared_error: 0.0853 - acc: 0.8839 - val_loss: 0.3051 - val_mean_squared_error: 0.0932 - val_acc: 0.8723\n",
      "Epoch 182/3000\n",
      " - 0s - loss: 0.2871 - mean_squared_error: 0.0846 - acc: 0.8888 - val_loss: 0.3050 - val_mean_squared_error: 0.0932 - val_acc: 0.8723\n",
      "Epoch 183/3000\n",
      " - 0s - loss: 0.2864 - mean_squared_error: 0.0843 - acc: 0.8814 - val_loss: 0.3049 - val_mean_squared_error: 0.0931 - val_acc: 0.8723\n",
      "Epoch 184/3000\n",
      " - 0s - loss: 0.2896 - mean_squared_error: 0.0857 - acc: 0.8863 - val_loss: 0.3047 - val_mean_squared_error: 0.0931 - val_acc: 0.8723\n",
      "Epoch 185/3000\n",
      " - 0s - loss: 0.2868 - mean_squared_error: 0.0847 - acc: 0.8875 - val_loss: 0.3044 - val_mean_squared_error: 0.0930 - val_acc: 0.8723\n",
      "Epoch 186/3000\n",
      " - 0s - loss: 0.2877 - mean_squared_error: 0.0849 - acc: 0.8851 - val_loss: 0.3042 - val_mean_squared_error: 0.0930 - val_acc: 0.8723\n",
      "Epoch 187/3000\n",
      " - 0s - loss: 0.2866 - mean_squared_error: 0.0846 - acc: 0.8912 - val_loss: 0.3039 - val_mean_squared_error: 0.0929 - val_acc: 0.8723\n",
      "Epoch 188/3000\n",
      " - 0s - loss: 0.2853 - mean_squared_error: 0.0840 - acc: 0.8875 - val_loss: 0.3035 - val_mean_squared_error: 0.0929 - val_acc: 0.8723\n",
      "Epoch 189/3000\n",
      " - 0s - loss: 0.2828 - mean_squared_error: 0.0834 - acc: 0.8900 - val_loss: 0.3032 - val_mean_squared_error: 0.0928 - val_acc: 0.8723\n",
      "Epoch 190/3000\n",
      " - 0s - loss: 0.2863 - mean_squared_error: 0.0847 - acc: 0.8863 - val_loss: 0.3029 - val_mean_squared_error: 0.0928 - val_acc: 0.8723\n",
      "Epoch 191/3000\n",
      " - 0s - loss: 0.2831 - mean_squared_error: 0.0834 - acc: 0.8875 - val_loss: 0.3027 - val_mean_squared_error: 0.0927 - val_acc: 0.8723\n",
      "Epoch 192/3000\n",
      " - 0s - loss: 0.2819 - mean_squared_error: 0.0827 - acc: 0.8888 - val_loss: 0.3026 - val_mean_squared_error: 0.0927 - val_acc: 0.8723\n",
      "Epoch 193/3000\n",
      " - 0s - loss: 0.2831 - mean_squared_error: 0.0832 - acc: 0.8912 - val_loss: 0.3024 - val_mean_squared_error: 0.0927 - val_acc: 0.8723\n",
      "Epoch 194/3000\n",
      " - 0s - loss: 0.2812 - mean_squared_error: 0.0831 - acc: 0.8888 - val_loss: 0.3023 - val_mean_squared_error: 0.0927 - val_acc: 0.8723\n",
      "Epoch 195/3000\n",
      " - 0s - loss: 0.2771 - mean_squared_error: 0.0813 - acc: 0.8936 - val_loss: 0.3023 - val_mean_squared_error: 0.0926 - val_acc: 0.8723\n",
      "Epoch 196/3000\n",
      " - 0s - loss: 0.2826 - mean_squared_error: 0.0832 - acc: 0.8900 - val_loss: 0.3022 - val_mean_squared_error: 0.0926 - val_acc: 0.8723\n",
      "Epoch 197/3000\n",
      " - 0s - loss: 0.2809 - mean_squared_error: 0.0827 - acc: 0.8863 - val_loss: 0.3022 - val_mean_squared_error: 0.0926 - val_acc: 0.8723\n",
      "Epoch 198/3000\n",
      " - 0s - loss: 0.2817 - mean_squared_error: 0.0827 - acc: 0.8900 - val_loss: 0.3020 - val_mean_squared_error: 0.0926 - val_acc: 0.8723\n",
      "Epoch 199/3000\n",
      " - 0s - loss: 0.2823 - mean_squared_error: 0.0835 - acc: 0.8875 - val_loss: 0.3019 - val_mean_squared_error: 0.0926 - val_acc: 0.8723\n",
      "Epoch 200/3000\n",
      " - 0s - loss: 0.2801 - mean_squared_error: 0.0826 - acc: 0.8875 - val_loss: 0.3017 - val_mean_squared_error: 0.0925 - val_acc: 0.8723\n",
      "Epoch 201/3000\n",
      " - 0s - loss: 0.2820 - mean_squared_error: 0.0835 - acc: 0.8875 - val_loss: 0.3015 - val_mean_squared_error: 0.0925 - val_acc: 0.8723\n",
      "Epoch 202/3000\n",
      " - 0s - loss: 0.2811 - mean_squared_error: 0.0828 - acc: 0.8875 - val_loss: 0.3012 - val_mean_squared_error: 0.0925 - val_acc: 0.8723\n",
      "Epoch 203/3000\n",
      " - 0s - loss: 0.2797 - mean_squared_error: 0.0820 - acc: 0.8900 - val_loss: 0.3009 - val_mean_squared_error: 0.0924 - val_acc: 0.8723\n",
      "Epoch 204/3000\n",
      " - 0s - loss: 0.2780 - mean_squared_error: 0.0816 - acc: 0.8900 - val_loss: 0.3006 - val_mean_squared_error: 0.0924 - val_acc: 0.8759\n",
      "Epoch 205/3000\n",
      " - 0s - loss: 0.2790 - mean_squared_error: 0.0822 - acc: 0.8900 - val_loss: 0.3003 - val_mean_squared_error: 0.0923 - val_acc: 0.8759\n",
      "Epoch 206/3000\n",
      " - 0s - loss: 0.2763 - mean_squared_error: 0.0814 - acc: 0.8900 - val_loss: 0.3001 - val_mean_squared_error: 0.0923 - val_acc: 0.8759\n",
      "Epoch 207/3000\n",
      " - 0s - loss: 0.2755 - mean_squared_error: 0.0817 - acc: 0.8851 - val_loss: 0.3000 - val_mean_squared_error: 0.0923 - val_acc: 0.8759\n",
      "Epoch 208/3000\n",
      " - 0s - loss: 0.2758 - mean_squared_error: 0.0808 - acc: 0.8924 - val_loss: 0.2998 - val_mean_squared_error: 0.0922 - val_acc: 0.8723\n",
      "Epoch 209/3000\n",
      " - 0s - loss: 0.2779 - mean_squared_error: 0.0818 - acc: 0.8912 - val_loss: 0.2997 - val_mean_squared_error: 0.0922 - val_acc: 0.8723\n",
      "Epoch 210/3000\n",
      " - 0s - loss: 0.2742 - mean_squared_error: 0.0806 - acc: 0.8875 - val_loss: 0.2997 - val_mean_squared_error: 0.0922 - val_acc: 0.8723\n",
      "Epoch 211/3000\n",
      " - 0s - loss: 0.2765 - mean_squared_error: 0.0816 - acc: 0.8875 - val_loss: 0.2997 - val_mean_squared_error: 0.0922 - val_acc: 0.8723\n",
      "Epoch 212/3000\n",
      " - 0s - loss: 0.2771 - mean_squared_error: 0.0816 - acc: 0.8912 - val_loss: 0.2996 - val_mean_squared_error: 0.0922 - val_acc: 0.8723\n",
      "Epoch 213/3000\n",
      " - 0s - loss: 0.2724 - mean_squared_error: 0.0797 - acc: 0.8912 - val_loss: 0.2995 - val_mean_squared_error: 0.0922 - val_acc: 0.8723\n",
      "Epoch 214/3000\n",
      " - 0s - loss: 0.2754 - mean_squared_error: 0.0809 - acc: 0.8961 - val_loss: 0.2993 - val_mean_squared_error: 0.0922 - val_acc: 0.8723\n",
      "Epoch 215/3000\n",
      " - 0s - loss: 0.2749 - mean_squared_error: 0.0811 - acc: 0.8912 - val_loss: 0.2992 - val_mean_squared_error: 0.0922 - val_acc: 0.8723\n",
      "Epoch 216/3000\n",
      " - 0s - loss: 0.2749 - mean_squared_error: 0.0811 - acc: 0.8924 - val_loss: 0.2990 - val_mean_squared_error: 0.0921 - val_acc: 0.8723\n",
      "Epoch 217/3000\n",
      " - 0s - loss: 0.2760 - mean_squared_error: 0.0812 - acc: 0.8875 - val_loss: 0.2988 - val_mean_squared_error: 0.0921 - val_acc: 0.8723\n",
      "Epoch 218/3000\n",
      " - 0s - loss: 0.2737 - mean_squared_error: 0.0806 - acc: 0.8863 - val_loss: 0.2985 - val_mean_squared_error: 0.0921 - val_acc: 0.8723\n",
      "Epoch 219/3000\n",
      " - 0s - loss: 0.2717 - mean_squared_error: 0.0798 - acc: 0.8949 - val_loss: 0.2983 - val_mean_squared_error: 0.0920 - val_acc: 0.8723\n",
      "Epoch 220/3000\n",
      " - 0s - loss: 0.2750 - mean_squared_error: 0.0810 - acc: 0.8851 - val_loss: 0.2981 - val_mean_squared_error: 0.0920 - val_acc: 0.8723\n",
      "Epoch 221/3000\n",
      " - 0s - loss: 0.2697 - mean_squared_error: 0.0793 - acc: 0.8924 - val_loss: 0.2980 - val_mean_squared_error: 0.0920 - val_acc: 0.8723\n",
      "Epoch 222/3000\n",
      " - 0s - loss: 0.2743 - mean_squared_error: 0.0809 - acc: 0.8900 - val_loss: 0.2979 - val_mean_squared_error: 0.0920 - val_acc: 0.8723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/3000\n",
      " - 0s - loss: 0.2727 - mean_squared_error: 0.0804 - acc: 0.8863 - val_loss: 0.2978 - val_mean_squared_error: 0.0919 - val_acc: 0.8723\n",
      "Epoch 224/3000\n",
      " - 0s - loss: 0.2708 - mean_squared_error: 0.0798 - acc: 0.8888 - val_loss: 0.2977 - val_mean_squared_error: 0.0919 - val_acc: 0.8723\n",
      "Epoch 225/3000\n",
      " - 0s - loss: 0.2715 - mean_squared_error: 0.0800 - acc: 0.8888 - val_loss: 0.2977 - val_mean_squared_error: 0.0919 - val_acc: 0.8723\n",
      "Epoch 226/3000\n",
      " - 0s - loss: 0.2712 - mean_squared_error: 0.0801 - acc: 0.8912 - val_loss: 0.2976 - val_mean_squared_error: 0.0919 - val_acc: 0.8723\n",
      "Epoch 227/3000\n",
      " - 0s - loss: 0.2722 - mean_squared_error: 0.0803 - acc: 0.8924 - val_loss: 0.2976 - val_mean_squared_error: 0.0919 - val_acc: 0.8723\n",
      "Epoch 228/3000\n",
      " - 0s - loss: 0.2709 - mean_squared_error: 0.0798 - acc: 0.8900 - val_loss: 0.2975 - val_mean_squared_error: 0.0919 - val_acc: 0.8759\n",
      "Epoch 229/3000\n",
      " - 0s - loss: 0.2684 - mean_squared_error: 0.0789 - acc: 0.8924 - val_loss: 0.2974 - val_mean_squared_error: 0.0919 - val_acc: 0.8759\n",
      "Epoch 230/3000\n",
      " - 0s - loss: 0.2700 - mean_squared_error: 0.0793 - acc: 0.8924 - val_loss: 0.2973 - val_mean_squared_error: 0.0919 - val_acc: 0.8759\n",
      "Epoch 231/3000\n",
      " - 0s - loss: 0.2686 - mean_squared_error: 0.0790 - acc: 0.8888 - val_loss: 0.2971 - val_mean_squared_error: 0.0918 - val_acc: 0.8759\n",
      "Epoch 232/3000\n",
      " - 0s - loss: 0.2667 - mean_squared_error: 0.0783 - acc: 0.8961 - val_loss: 0.2970 - val_mean_squared_error: 0.0918 - val_acc: 0.8759\n",
      "Epoch 233/3000\n",
      " - 0s - loss: 0.2681 - mean_squared_error: 0.0786 - acc: 0.8912 - val_loss: 0.2968 - val_mean_squared_error: 0.0918 - val_acc: 0.8759\n",
      "Epoch 234/3000\n",
      " - 0s - loss: 0.2671 - mean_squared_error: 0.0785 - acc: 0.8912 - val_loss: 0.2967 - val_mean_squared_error: 0.0918 - val_acc: 0.8759\n",
      "Epoch 235/3000\n",
      " - 0s - loss: 0.2665 - mean_squared_error: 0.0785 - acc: 0.8936 - val_loss: 0.2966 - val_mean_squared_error: 0.0918 - val_acc: 0.8759\n",
      "Epoch 236/3000\n",
      " - 0s - loss: 0.2643 - mean_squared_error: 0.0778 - acc: 0.8900 - val_loss: 0.2965 - val_mean_squared_error: 0.0918 - val_acc: 0.8759\n",
      "Epoch 237/3000\n",
      " - 0s - loss: 0.2641 - mean_squared_error: 0.0773 - acc: 0.8912 - val_loss: 0.2964 - val_mean_squared_error: 0.0918 - val_acc: 0.8759\n",
      "Epoch 238/3000\n",
      " - 0s - loss: 0.2649 - mean_squared_error: 0.0775 - acc: 0.8936 - val_loss: 0.2963 - val_mean_squared_error: 0.0918 - val_acc: 0.8759\n",
      "Epoch 239/3000\n",
      " - 0s - loss: 0.2651 - mean_squared_error: 0.0779 - acc: 0.8924 - val_loss: 0.2963 - val_mean_squared_error: 0.0918 - val_acc: 0.8759\n",
      "Epoch 240/3000\n",
      " - 0s - loss: 0.2626 - mean_squared_error: 0.0773 - acc: 0.8912 - val_loss: 0.2962 - val_mean_squared_error: 0.0918 - val_acc: 0.8759\n",
      "Epoch 241/3000\n",
      " - 0s - loss: 0.2654 - mean_squared_error: 0.0780 - acc: 0.8924 - val_loss: 0.2962 - val_mean_squared_error: 0.0918 - val_acc: 0.8759\n",
      "Epoch 242/3000\n",
      " - 0s - loss: 0.2667 - mean_squared_error: 0.0783 - acc: 0.8998 - val_loss: 0.2962 - val_mean_squared_error: 0.0918 - val_acc: 0.8759\n",
      "Epoch 243/3000\n",
      " - 0s - loss: 0.2653 - mean_squared_error: 0.0778 - acc: 0.8936 - val_loss: 0.2961 - val_mean_squared_error: 0.0918 - val_acc: 0.8759\n",
      "Epoch 244/3000\n",
      " - 0s - loss: 0.2650 - mean_squared_error: 0.0781 - acc: 0.8924 - val_loss: 0.2960 - val_mean_squared_error: 0.0918 - val_acc: 0.8759\n",
      "Epoch 245/3000\n",
      " - 0s - loss: 0.2662 - mean_squared_error: 0.0784 - acc: 0.8912 - val_loss: 0.2959 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 246/3000\n",
      " - 0s - loss: 0.2665 - mean_squared_error: 0.0784 - acc: 0.8961 - val_loss: 0.2958 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 247/3000\n",
      " - 0s - loss: 0.2619 - mean_squared_error: 0.0767 - acc: 0.8949 - val_loss: 0.2957 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 248/3000\n",
      " - 0s - loss: 0.2625 - mean_squared_error: 0.0773 - acc: 0.8949 - val_loss: 0.2956 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 249/3000\n",
      " - 0s - loss: 0.2644 - mean_squared_error: 0.0779 - acc: 0.8924 - val_loss: 0.2954 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 250/3000\n",
      " - 0s - loss: 0.2638 - mean_squared_error: 0.0776 - acc: 0.8936 - val_loss: 0.2953 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 251/3000\n",
      " - 0s - loss: 0.2579 - mean_squared_error: 0.0755 - acc: 0.8985 - val_loss: 0.2953 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 252/3000\n",
      " - 0s - loss: 0.2631 - mean_squared_error: 0.0779 - acc: 0.8949 - val_loss: 0.2952 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 253/3000\n",
      " - 0s - loss: 0.2623 - mean_squared_error: 0.0774 - acc: 0.8961 - val_loss: 0.2952 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 254/3000\n",
      " - 0s - loss: 0.2616 - mean_squared_error: 0.0769 - acc: 0.8949 - val_loss: 0.2951 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 255/3000\n",
      " - 0s - loss: 0.2609 - mean_squared_error: 0.0769 - acc: 0.8900 - val_loss: 0.2951 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 256/3000\n",
      " - 0s - loss: 0.2622 - mean_squared_error: 0.0768 - acc: 0.8924 - val_loss: 0.2951 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 257/3000\n",
      " - 0s - loss: 0.2628 - mean_squared_error: 0.0776 - acc: 0.8900 - val_loss: 0.2951 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 258/3000\n",
      " - 0s - loss: 0.2625 - mean_squared_error: 0.0774 - acc: 0.8924 - val_loss: 0.2950 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 259/3000\n",
      " - 0s - loss: 0.2598 - mean_squared_error: 0.0761 - acc: 0.8936 - val_loss: 0.2949 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 260/3000\n",
      " - 0s - loss: 0.2577 - mean_squared_error: 0.0757 - acc: 0.8961 - val_loss: 0.2948 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 261/3000\n",
      " - 0s - loss: 0.2575 - mean_squared_error: 0.0759 - acc: 0.8961 - val_loss: 0.2947 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 262/3000\n",
      " - 0s - loss: 0.2564 - mean_squared_error: 0.0752 - acc: 0.8985 - val_loss: 0.2946 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 263/3000\n",
      " - 0s - loss: 0.2579 - mean_squared_error: 0.0757 - acc: 0.8985 - val_loss: 0.2945 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 264/3000\n",
      " - 0s - loss: 0.2576 - mean_squared_error: 0.0756 - acc: 0.9010 - val_loss: 0.2944 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 265/3000\n",
      " - 0s - loss: 0.2556 - mean_squared_error: 0.0746 - acc: 0.8961 - val_loss: 0.2942 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 266/3000\n",
      " - 0s - loss: 0.2565 - mean_squared_error: 0.0758 - acc: 0.8961 - val_loss: 0.2942 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 267/3000\n",
      " - 0s - loss: 0.2540 - mean_squared_error: 0.0744 - acc: 0.8949 - val_loss: 0.2941 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 268/3000\n",
      " - 0s - loss: 0.2586 - mean_squared_error: 0.0765 - acc: 0.8900 - val_loss: 0.2940 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 269/3000\n",
      " - 0s - loss: 0.2532 - mean_squared_error: 0.0743 - acc: 0.8961 - val_loss: 0.2940 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 270/3000\n",
      " - 0s - loss: 0.2568 - mean_squared_error: 0.0754 - acc: 0.9059 - val_loss: 0.2940 - val_mean_squared_error: 0.0916 - val_acc: 0.8759\n",
      "Epoch 271/3000\n",
      " - 0s - loss: 0.2565 - mean_squared_error: 0.0755 - acc: 0.9034 - val_loss: 0.2940 - val_mean_squared_error: 0.0916 - val_acc: 0.8759\n",
      "Epoch 272/3000\n",
      " - 0s - loss: 0.2531 - mean_squared_error: 0.0745 - acc: 0.8912 - val_loss: 0.2940 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 273/3000\n",
      " - 0s - loss: 0.2576 - mean_squared_error: 0.0759 - acc: 0.8949 - val_loss: 0.2939 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 274/3000\n",
      " - 0s - loss: 0.2579 - mean_squared_error: 0.0760 - acc: 0.8985 - val_loss: 0.2939 - val_mean_squared_error: 0.0916 - val_acc: 0.8759\n",
      "Epoch 275/3000\n",
      " - 0s - loss: 0.2541 - mean_squared_error: 0.0747 - acc: 0.8973 - val_loss: 0.2938 - val_mean_squared_error: 0.0916 - val_acc: 0.8759\n",
      "Epoch 276/3000\n",
      " - 0s - loss: 0.2560 - mean_squared_error: 0.0751 - acc: 0.9022 - val_loss: 0.2938 - val_mean_squared_error: 0.0917 - val_acc: 0.8759\n",
      "Epoch 277/3000\n",
      " - 0s - loss: 0.2531 - mean_squared_error: 0.0740 - acc: 0.8998 - val_loss: 0.2937 - val_mean_squared_error: 0.0916 - val_acc: 0.8759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/3000\n",
      " - 0s - loss: 0.2533 - mean_squared_error: 0.0738 - acc: 0.9034 - val_loss: 0.2937 - val_mean_squared_error: 0.0916 - val_acc: 0.8723\n",
      "Epoch 279/3000\n",
      " - 0s - loss: 0.2539 - mean_squared_error: 0.0746 - acc: 0.8961 - val_loss: 0.2936 - val_mean_squared_error: 0.0916 - val_acc: 0.8723\n",
      "Epoch 280/3000\n",
      " - 0s - loss: 0.2573 - mean_squared_error: 0.0759 - acc: 0.8936 - val_loss: 0.2935 - val_mean_squared_error: 0.0916 - val_acc: 0.8723\n",
      "Epoch 281/3000\n",
      " - 0s - loss: 0.2539 - mean_squared_error: 0.0749 - acc: 0.8998 - val_loss: 0.2935 - val_mean_squared_error: 0.0916 - val_acc: 0.8723\n",
      "Epoch 282/3000\n",
      " - 0s - loss: 0.2523 - mean_squared_error: 0.0739 - acc: 0.9022 - val_loss: 0.2934 - val_mean_squared_error: 0.0916 - val_acc: 0.8723\n",
      "Epoch 283/3000\n",
      " - 0s - loss: 0.2515 - mean_squared_error: 0.0739 - acc: 0.8985 - val_loss: 0.2934 - val_mean_squared_error: 0.0916 - val_acc: 0.8723\n",
      "Epoch 284/3000\n",
      " - 0s - loss: 0.2539 - mean_squared_error: 0.0747 - acc: 0.8998 - val_loss: 0.2934 - val_mean_squared_error: 0.0916 - val_acc: 0.8723\n",
      "Epoch 285/3000\n",
      " - 0s - loss: 0.2531 - mean_squared_error: 0.0744 - acc: 0.9010 - val_loss: 0.2933 - val_mean_squared_error: 0.0916 - val_acc: 0.8723\n",
      "Epoch 286/3000\n",
      " - 0s - loss: 0.2521 - mean_squared_error: 0.0739 - acc: 0.9010 - val_loss: 0.2933 - val_mean_squared_error: 0.0916 - val_acc: 0.8723\n",
      "Epoch 287/3000\n",
      " - 0s - loss: 0.2500 - mean_squared_error: 0.0735 - acc: 0.8985 - val_loss: 0.2933 - val_mean_squared_error: 0.0916 - val_acc: 0.8723\n",
      "Epoch 288/3000\n",
      " - 0s - loss: 0.2521 - mean_squared_error: 0.0743 - acc: 0.8985 - val_loss: 0.2932 - val_mean_squared_error: 0.0916 - val_acc: 0.8723\n",
      "Epoch 289/3000\n",
      " - 0s - loss: 0.2522 - mean_squared_error: 0.0739 - acc: 0.9010 - val_loss: 0.2932 - val_mean_squared_error: 0.0916 - val_acc: 0.8723\n",
      "Epoch 290/3000\n",
      " - 0s - loss: 0.2512 - mean_squared_error: 0.0738 - acc: 0.9034 - val_loss: 0.2931 - val_mean_squared_error: 0.0915 - val_acc: 0.8723\n",
      "Epoch 291/3000\n",
      " - 0s - loss: 0.2497 - mean_squared_error: 0.0728 - acc: 0.8973 - val_loss: 0.2930 - val_mean_squared_error: 0.0915 - val_acc: 0.8723\n",
      "Epoch 292/3000\n",
      " - 0s - loss: 0.2509 - mean_squared_error: 0.0736 - acc: 0.8998 - val_loss: 0.2930 - val_mean_squared_error: 0.0915 - val_acc: 0.8723\n",
      "Epoch 293/3000\n",
      " - 0s - loss: 0.2508 - mean_squared_error: 0.0737 - acc: 0.8998 - val_loss: 0.2928 - val_mean_squared_error: 0.0915 - val_acc: 0.8686\n",
      "Epoch 294/3000\n",
      " - 0s - loss: 0.2491 - mean_squared_error: 0.0728 - acc: 0.8998 - val_loss: 0.2927 - val_mean_squared_error: 0.0915 - val_acc: 0.8686\n",
      "Epoch 295/3000\n",
      " - 0s - loss: 0.2493 - mean_squared_error: 0.0731 - acc: 0.9010 - val_loss: 0.2926 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 296/3000\n",
      " - 0s - loss: 0.2492 - mean_squared_error: 0.0730 - acc: 0.9034 - val_loss: 0.2924 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 297/3000\n",
      " - 0s - loss: 0.2466 - mean_squared_error: 0.0724 - acc: 0.9010 - val_loss: 0.2924 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 298/3000\n",
      " - 0s - loss: 0.2458 - mean_squared_error: 0.0724 - acc: 0.8973 - val_loss: 0.2923 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 299/3000\n",
      " - 0s - loss: 0.2451 - mean_squared_error: 0.0716 - acc: 0.9022 - val_loss: 0.2922 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 300/3000\n",
      " - 0s - loss: 0.2489 - mean_squared_error: 0.0730 - acc: 0.9034 - val_loss: 0.2922 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 301/3000\n",
      " - 0s - loss: 0.2472 - mean_squared_error: 0.0725 - acc: 0.9022 - val_loss: 0.2922 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 302/3000\n",
      " - 0s - loss: 0.2466 - mean_squared_error: 0.0725 - acc: 0.8985 - val_loss: 0.2922 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 303/3000\n",
      " - 0s - loss: 0.2458 - mean_squared_error: 0.0720 - acc: 0.9034 - val_loss: 0.2922 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 304/3000\n",
      " - 0s - loss: 0.2461 - mean_squared_error: 0.0720 - acc: 0.9046 - val_loss: 0.2921 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 305/3000\n",
      " - 0s - loss: 0.2453 - mean_squared_error: 0.0719 - acc: 0.9010 - val_loss: 0.2921 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 306/3000\n",
      " - 0s - loss: 0.2487 - mean_squared_error: 0.0728 - acc: 0.9059 - val_loss: 0.2920 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 307/3000\n",
      " - 0s - loss: 0.2460 - mean_squared_error: 0.0722 - acc: 0.9034 - val_loss: 0.2920 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 308/3000\n",
      " - 0s - loss: 0.2453 - mean_squared_error: 0.0718 - acc: 0.9046 - val_loss: 0.2919 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 309/3000\n",
      " - 0s - loss: 0.2470 - mean_squared_error: 0.0726 - acc: 0.9083 - val_loss: 0.2919 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 310/3000\n",
      " - 0s - loss: 0.2456 - mean_squared_error: 0.0721 - acc: 0.8973 - val_loss: 0.2919 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 311/3000\n",
      " - 0s - loss: 0.2444 - mean_squared_error: 0.0717 - acc: 0.9046 - val_loss: 0.2919 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 312/3000\n",
      " - 0s - loss: 0.2447 - mean_squared_error: 0.0719 - acc: 0.9010 - val_loss: 0.2919 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 313/3000\n",
      " - 0s - loss: 0.2479 - mean_squared_error: 0.0730 - acc: 0.8973 - val_loss: 0.2919 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 314/3000\n",
      " - 0s - loss: 0.2456 - mean_squared_error: 0.0720 - acc: 0.9034 - val_loss: 0.2919 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 315/3000\n",
      " - 0s - loss: 0.2429 - mean_squared_error: 0.0711 - acc: 0.9059 - val_loss: 0.2919 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 316/3000\n",
      " - 0s - loss: 0.2432 - mean_squared_error: 0.0714 - acc: 0.8973 - val_loss: 0.2919 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 317/3000\n",
      " - 0s - loss: 0.2416 - mean_squared_error: 0.0708 - acc: 0.9010 - val_loss: 0.2919 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 318/3000\n",
      " - 0s - loss: 0.2452 - mean_squared_error: 0.0722 - acc: 0.8998 - val_loss: 0.2919 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 319/3000\n",
      " - 0s - loss: 0.2450 - mean_squared_error: 0.0716 - acc: 0.9022 - val_loss: 0.2919 - val_mean_squared_error: 0.0914 - val_acc: 0.8686\n",
      "Epoch 320/3000\n",
      " - 0s - loss: 0.2419 - mean_squared_error: 0.0708 - acc: 0.9046 - val_loss: 0.2920 - val_mean_squared_error: 0.0915 - val_acc: 0.8686\n",
      "Epoch 321/3000\n",
      " - 0s - loss: 0.2442 - mean_squared_error: 0.0718 - acc: 0.9071 - val_loss: 0.2920 - val_mean_squared_error: 0.0915 - val_acc: 0.8650\n",
      "Epoch 322/3000\n",
      " - 0s - loss: 0.2414 - mean_squared_error: 0.0706 - acc: 0.9095 - val_loss: 0.2921 - val_mean_squared_error: 0.0915 - val_acc: 0.8650\n",
      "Epoch 323/3000\n",
      " - 0s - loss: 0.2425 - mean_squared_error: 0.0710 - acc: 0.9083 - val_loss: 0.2922 - val_mean_squared_error: 0.0916 - val_acc: 0.8650\n",
      "Epoch 324/3000\n",
      " - 0s - loss: 0.2393 - mean_squared_error: 0.0702 - acc: 0.9022 - val_loss: 0.2922 - val_mean_squared_error: 0.0916 - val_acc: 0.8686\n",
      "Epoch 325/3000\n",
      " - 0s - loss: 0.2428 - mean_squared_error: 0.0713 - acc: 0.9059 - val_loss: 0.2922 - val_mean_squared_error: 0.0916 - val_acc: 0.8686\n",
      "Epoch 326/3000\n",
      " - 0s - loss: 0.2434 - mean_squared_error: 0.0712 - acc: 0.9046 - val_loss: 0.2922 - val_mean_squared_error: 0.0916 - val_acc: 0.8686\n",
      "Epoch 327/3000\n",
      " - 0s - loss: 0.2413 - mean_squared_error: 0.0709 - acc: 0.9046 - val_loss: 0.2922 - val_mean_squared_error: 0.0916 - val_acc: 0.8686\n",
      "Epoch 328/3000\n",
      " - 0s - loss: 0.2402 - mean_squared_error: 0.0703 - acc: 0.9071 - val_loss: 0.2922 - val_mean_squared_error: 0.0916 - val_acc: 0.8686\n",
      "Epoch 329/3000\n",
      " - 0s - loss: 0.2408 - mean_squared_error: 0.0705 - acc: 0.9059 - val_loss: 0.2922 - val_mean_squared_error: 0.0916 - val_acc: 0.8686\n",
      "Epoch 330/3000\n",
      " - 0s - loss: 0.2414 - mean_squared_error: 0.0706 - acc: 0.9059 - val_loss: 0.2922 - val_mean_squared_error: 0.0916 - val_acc: 0.8686\n",
      "Epoch 331/3000\n",
      " - 0s - loss: 0.2393 - mean_squared_error: 0.0696 - acc: 0.9071 - val_loss: 0.2922 - val_mean_squared_error: 0.0916 - val_acc: 0.8686\n",
      "Epoch 332/3000\n",
      " - 0s - loss: 0.2405 - mean_squared_error: 0.0708 - acc: 0.9059 - val_loss: 0.2922 - val_mean_squared_error: 0.0916 - val_acc: 0.8686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/3000\n",
      " - 0s - loss: 0.2386 - mean_squared_error: 0.0700 - acc: 0.9071 - val_loss: 0.2923 - val_mean_squared_error: 0.0917 - val_acc: 0.8686\n",
      "Epoch 334/3000\n",
      " - 0s - loss: 0.2399 - mean_squared_error: 0.0705 - acc: 0.9034 - val_loss: 0.2923 - val_mean_squared_error: 0.0917 - val_acc: 0.8686\n",
      "Epoch 335/3000\n",
      " - 0s - loss: 0.2381 - mean_squared_error: 0.0696 - acc: 0.9034 - val_loss: 0.2923 - val_mean_squared_error: 0.0917 - val_acc: 0.8686\n",
      "Epoch 336/3000\n",
      " - 0s - loss: 0.2426 - mean_squared_error: 0.0711 - acc: 0.9059 - val_loss: 0.2923 - val_mean_squared_error: 0.0917 - val_acc: 0.8686\n",
      "Epoch 337/3000\n",
      " - 0s - loss: 0.2408 - mean_squared_error: 0.0706 - acc: 0.9034 - val_loss: 0.2924 - val_mean_squared_error: 0.0917 - val_acc: 0.8686\n",
      "Epoch 338/3000\n",
      " - 0s - loss: 0.2400 - mean_squared_error: 0.0705 - acc: 0.9022 - val_loss: 0.2924 - val_mean_squared_error: 0.0918 - val_acc: 0.8686\n",
      "Epoch 339/3000\n",
      " - 0s - loss: 0.2390 - mean_squared_error: 0.0699 - acc: 0.9059 - val_loss: 0.2925 - val_mean_squared_error: 0.0918 - val_acc: 0.8686\n",
      "Epoch 340/3000\n",
      " - 0s - loss: 0.2404 - mean_squared_error: 0.0708 - acc: 0.9034 - val_loss: 0.2925 - val_mean_squared_error: 0.0918 - val_acc: 0.8686\n",
      "Epoch 341/3000\n",
      " - 0s - loss: 0.2367 - mean_squared_error: 0.0691 - acc: 0.9095 - val_loss: 0.2925 - val_mean_squared_error: 0.0918 - val_acc: 0.8686\n",
      "Epoch 342/3000\n",
      " - 0s - loss: 0.2357 - mean_squared_error: 0.0687 - acc: 0.9083 - val_loss: 0.2924 - val_mean_squared_error: 0.0918 - val_acc: 0.8686\n",
      "Epoch 343/3000\n",
      " - 0s - loss: 0.2348 - mean_squared_error: 0.0686 - acc: 0.9071 - val_loss: 0.2924 - val_mean_squared_error: 0.0918 - val_acc: 0.8686\n",
      "Epoch 344/3000\n",
      " - 0s - loss: 0.2332 - mean_squared_error: 0.0682 - acc: 0.9059 - val_loss: 0.2923 - val_mean_squared_error: 0.0918 - val_acc: 0.8686\n",
      "Epoch 345/3000\n",
      " - 0s - loss: 0.2388 - mean_squared_error: 0.0703 - acc: 0.9034 - val_loss: 0.2923 - val_mean_squared_error: 0.0918 - val_acc: 0.8686\n",
      "Epoch 346/3000\n",
      " - 0s - loss: 0.2341 - mean_squared_error: 0.0685 - acc: 0.9095 - val_loss: 0.2923 - val_mean_squared_error: 0.0918 - val_acc: 0.8686\n",
      "Epoch 347/3000\n",
      " - 0s - loss: 0.2348 - mean_squared_error: 0.0684 - acc: 0.9108 - val_loss: 0.2923 - val_mean_squared_error: 0.0918 - val_acc: 0.8686\n",
      "Epoch 348/3000\n",
      " - 0s - loss: 0.2362 - mean_squared_error: 0.0693 - acc: 0.9010 - val_loss: 0.2923 - val_mean_squared_error: 0.0918 - val_acc: 0.8686\n",
      "Epoch 349/3000\n",
      " - 0s - loss: 0.2387 - mean_squared_error: 0.0699 - acc: 0.9034 - val_loss: 0.2922 - val_mean_squared_error: 0.0918 - val_acc: 0.8686\n",
      "Epoch 350/3000\n",
      " - 0s - loss: 0.2378 - mean_squared_error: 0.0699 - acc: 0.9120 - val_loss: 0.2922 - val_mean_squared_error: 0.0918 - val_acc: 0.8686\n",
      "Epoch 351/3000\n",
      " - 0s - loss: 0.2379 - mean_squared_error: 0.0699 - acc: 0.9046 - val_loss: 0.2921 - val_mean_squared_error: 0.0917 - val_acc: 0.8686\n",
      "Epoch 352/3000\n",
      " - 0s - loss: 0.2370 - mean_squared_error: 0.0690 - acc: 0.9059 - val_loss: 0.2920 - val_mean_squared_error: 0.0917 - val_acc: 0.8686\n",
      "Epoch 353/3000\n",
      " - 0s - loss: 0.2339 - mean_squared_error: 0.0683 - acc: 0.9108 - val_loss: 0.2920 - val_mean_squared_error: 0.0917 - val_acc: 0.8686\n",
      "Epoch 354/3000\n",
      " - 0s - loss: 0.2345 - mean_squared_error: 0.0688 - acc: 0.9071 - val_loss: 0.2920 - val_mean_squared_error: 0.0917 - val_acc: 0.8650\n",
      "Epoch 355/3000\n",
      " - 0s - loss: 0.2316 - mean_squared_error: 0.0673 - acc: 0.9120 - val_loss: 0.2919 - val_mean_squared_error: 0.0917 - val_acc: 0.8650\n",
      "Epoch 356/3000\n",
      " - 0s - loss: 0.2315 - mean_squared_error: 0.0678 - acc: 0.9095 - val_loss: 0.2919 - val_mean_squared_error: 0.0917 - val_acc: 0.8650\n",
      "Epoch 357/3000\n",
      " - 0s - loss: 0.2310 - mean_squared_error: 0.0675 - acc: 0.9120 - val_loss: 0.2919 - val_mean_squared_error: 0.0917 - val_acc: 0.8650\n",
      "Epoch 358/3000\n",
      " - 0s - loss: 0.2342 - mean_squared_error: 0.0685 - acc: 0.9034 - val_loss: 0.2919 - val_mean_squared_error: 0.0917 - val_acc: 0.8650\n",
      "Epoch 359/3000\n",
      " - 0s - loss: 0.2319 - mean_squared_error: 0.0683 - acc: 0.9022 - val_loss: 0.2919 - val_mean_squared_error: 0.0917 - val_acc: 0.8650\n",
      "274/274 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['loss', 'mean_squared_error', 'acc'],\n",
       " [0.29186007423992577, 0.09165919387210024, 0.8649635040847055])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(x_train_norm, y_train, validation_data=(x_test_norm, y_test), epochs=3000, batch_size=512,\n",
    "          callbacks=[clr, stop], verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(x_test_norm, y_test)\n",
    "model.metrics_names, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_preds = model.predict_classes(x_test_norm)\n",
    "nn_pos = model.predict_proba(x_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.864963503649635,\n",
       " 0.30275269850951353,\n",
       " 0.9420821114369502,\n",
       " 0.2918600827710242)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(nn_preds), rmse(nn_pos), auroc(nn_pos), logloss(nn_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8613138686131386,\n",
       " 0.3028432195846944,\n",
       " 0.9420821114369502,\n",
       " 0.2922430505408254)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.864963503649635,\n",
    " 0.30275269850951353,\n",
    " 0.9420821114369502,\n",
    " 0.2918600827710242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['gbc_preds'] = gbc.predict_proba(x_train).T[1]\n",
    "test_df['gbc_preds'] = gbc.predict_proba(x_test).T[1]\n",
    "train_df['rfc_preds'] = rfc.predict_proba(x_train).T[1]\n",
    "test_df['rfc_preds'] = rfc.predict_proba(x_test).T[1]\n",
    "train_df['etc_preds'] = etc.predict_proba(x_train).T[1]\n",
    "test_df['etc_preds'] = etc.predict_proba(x_test).T[1]\n",
    "train_df['nn_preds'] = model.predict_proba(x_train_norm)\n",
    "test_df['nn_preds'] = model.predict_proba(x_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d.gone.neg.l1</th>\n",
       "      <th>d.gone.neg.l2</th>\n",
       "      <th>d.neg.frac.l3</th>\n",
       "      <th>week</th>\n",
       "      <th>camp.length</th>\n",
       "      <th>base.poll</th>\n",
       "      <th>y2000</th>\n",
       "      <th>y2002</th>\n",
       "      <th>y2004</th>\n",
       "      <th>y2006</th>\n",
       "      <th>...</th>\n",
       "      <th>deminc</th>\n",
       "      <th>dem.contrib.l1</th>\n",
       "      <th>dem.contrib.l2</th>\n",
       "      <th>rep.contrib.l1</th>\n",
       "      <th>rep.contrib.l2</th>\n",
       "      <th>d.gone.neg</th>\n",
       "      <th>gbc_preds</th>\n",
       "      <th>rfc_preds</th>\n",
       "      <th>etc_preds</th>\n",
       "      <th>nn_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11</td>\n",
       "      <td>23</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>38350.0</td>\n",
       "      <td>126536.00</td>\n",
       "      <td>132545.00</td>\n",
       "      <td>102559.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235871</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10</td>\n",
       "      <td>23</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>58035.0</td>\n",
       "      <td>38350.00</td>\n",
       "      <td>522327.00</td>\n",
       "      <td>132545.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.154327</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8</td>\n",
       "      <td>23</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>167280.0</td>\n",
       "      <td>67068.67</td>\n",
       "      <td>177739.44</td>\n",
       "      <td>138533.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.921011</td>\n",
       "      <td>0.958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.906002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7</td>\n",
       "      <td>23</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>389947.0</td>\n",
       "      <td>167280.00</td>\n",
       "      <td>543465.00</td>\n",
       "      <td>177739.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985290</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-6</td>\n",
       "      <td>23</td>\n",
       "      <td>45.744681</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>202734.0</td>\n",
       "      <td>389947.00</td>\n",
       "      <td>2415314.50</td>\n",
       "      <td>543465.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989649</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   d.gone.neg.l1  d.gone.neg.l2  d.neg.frac.l3  week  camp.length  base.poll  \\\n",
       "1              0              0       0.000000   -11           23  45.744681   \n",
       "2              0              0       0.000000   -10           23  45.744681   \n",
       "3              1              0       0.000000    -8           23  45.744681   \n",
       "4              1              1       0.000000    -7           23  45.744681   \n",
       "5              1              1       0.071429    -6           23  45.744681   \n",
       "\n",
       "   y2000  y2002  y2004  y2006    ...     deminc  dem.contrib.l1  \\\n",
       "1      0      1      0      0    ...          1         38350.0   \n",
       "2      0      1      0      0    ...          1         58035.0   \n",
       "3      0      1      0      0    ...          1        167280.0   \n",
       "4      0      1      0      0    ...          1        389947.0   \n",
       "5      0      1      0      0    ...          1        202734.0   \n",
       "\n",
       "   dem.contrib.l2  rep.contrib.l1  rep.contrib.l2  d.gone.neg  gbc_preds  \\\n",
       "1       126536.00       132545.00       102559.36           0   0.235871   \n",
       "2        38350.00       522327.00       132545.00           0   0.154327   \n",
       "3        67068.67       177739.44       138533.00           1   0.921011   \n",
       "4       167280.00       543465.00       177739.44           1   0.985290   \n",
       "5       389947.00      2415314.50       543465.00           1   0.989649   \n",
       "\n",
       "   rfc_preds  etc_preds  nn_preds  \n",
       "1      0.146        0.0  0.199028  \n",
       "2      0.084        0.0  0.283316  \n",
       "3      0.958        1.0  0.906002  \n",
       "4      0.998        1.0  0.974159  \n",
       "5      1.000        1.0  0.994450  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(f'{PATH}train_preds.csv')\n",
    "test_df.to_csv(f'{PATH}test_preds.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
